<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CS224W  3. Node Embeddings | aigonna</title><meta name="keywords" content="CS224W,Node embedding,DeepWalk,node2vec,Random Walk,Random-Walk Embeddings,Negative Sampling,Biased Random Walks,Anonymous Walk Embeddings"><meta name="author" content="aigonna"><meta name="copyright" content="aigonna"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="3. Node Embeddings1. Recap: Traditioal ML for Graphs 传统的图机器学习：  给定一个输入图，抽取节点、边和图级别特征, 学习一个能将这些特征映射到标签的模型(像SVM， NN…) 这个抽取不同级别特征的过程，就是特征工程feature engineering 学习到模型后拿来预测就是具体的下游预测任务  1. Graph representati">
<meta property="og:type" content="article">
<meta property="og:title" content="CS224W  3. Node Embeddings">
<meta property="og:url" content="http://aigonna.com/2022/03/03/CS224W_3.%20Node%20Embeddings/index.html">
<meta property="og:site_name" content="aigonna">
<meta property="og:description" content="3. Node Embeddings1. Recap: Traditioal ML for Graphs 传统的图机器学习：  给定一个输入图，抽取节点、边和图级别特征, 学习一个能将这些特征映射到标签的模型(像SVM， NN…) 这个抽取不同级别特征的过程，就是特征工程feature engineering 学习到模型后拿来预测就是具体的下游预测任务  1. Graph representati">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aigonna.com/img/imgs/14.jpg">
<meta property="article:published_time" content="2022-03-03T14:49:39.000Z">
<meta property="article:modified_time" content="2022-05-01T11:24:25.661Z">
<meta property="article:author" content="aigonna">
<meta property="article:tag" content="CS224W">
<meta property="article:tag" content="Node embedding">
<meta property="article:tag" content="DeepWalk">
<meta property="article:tag" content="node2vec">
<meta property="article:tag" content="Random Walk">
<meta property="article:tag" content="Random-Walk Embeddings">
<meta property="article:tag" content="Negative Sampling">
<meta property="article:tag" content="Biased Random Walks">
<meta property="article:tag" content="Anonymous Walk Embeddings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aigonna.com/img/imgs/14.jpg"><link rel="shortcut icon" href="/img/AI.png"><link rel="canonical" href="http://aigonna.com/2022/03/03/CS224W_3.%20Node%20Embeddings/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-RMGH8E0YEQ"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-RMGH8E0YEQ');
</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://fastly.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://fastly.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://fastly.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://fastly.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-01 19:24:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/AI.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">84</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">211</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/imgs/14.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">aigonna</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CS224W  3. Node Embeddings</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2022-03-03T14:49:39.000Z" title="undefined 2022-03-03 22:49:39">2022-03-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/GNN/">GNN</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="3-Node-Embeddings"><a href="#3-Node-Embeddings" class="headerlink" title="3. Node Embeddings"></a>3. Node Embeddings</h3><h4 id="1-Recap-Traditioal-ML-for-Graphs"><a href="#1-Recap-Traditioal-ML-for-Graphs" class="headerlink" title="1. Recap: Traditioal ML for Graphs"></a>1. Recap: Traditioal ML for Graphs</h4><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011916081.png" alt="image-20220323151923339" style="zoom:25%;" /></p>
<p><strong>传统的图机器学习</strong>：</p>
<ul>
<li>给定一个<strong>输入图</strong>，<strong>抽取节点、边和图级别特征</strong>, 学习一个能<strong>将这些特征映射到标签的模型</strong>(像SVM， NN…)</li>
<li>这个抽取不同级别特征的过程，就是<strong>特征工程feature engineering</strong></li>
<li>学习到模型后拿来预测就是具体的<strong>下游预测任务</strong></li>
</ul>
<h5 id="1-Graph-representation-learning"><a href="#1-Graph-representation-learning" class="headerlink" title="1. Graph representation learning"></a>1. Graph representation learning</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011916278.png" alt="image-20220323152545815" style="zoom:25%;" /></p>
<p><strong>图的表征学习</strong>：</p>
<p>目标：图机器学习的高效的<strong>任务无关特征</strong>学习。对于图，要抽取到任务无关的的特征，这样下游任务不同，也能用。</p>
<p>如上图，就是把节点u，拿函数<script type="math/tex">f: u \to \mathbb{R}^d</script>， 映射成向量v，<script type="math/tex">\mathbf{v} \in \mathbb{R}^d</script>. 这就是<strong>特征表示</strong>或者更具体地说<strong>embedding</strong>.</p>
<h5 id="2-Why-Embedding？"><a href="#2-Why-Embedding？" class="headerlink" title="2. Why Embedding？"></a>2. Why Embedding？</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917835.png" alt="image-20220323154010440" style="zoom:25%;" /></p>
<ul>
<li><strong>任务：映射节点到一个embedding 空间</strong><ul>
<li>节点间embeddings的相似性表示它们在网络中的相似性。如节点彼此接近(被同一条边连接)，其embedding相似度要高。</li>
<li>编码网络信息</li>
<li>有潜力为许多下游任务做预测</li>
</ul>
</li>
</ul>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011921312.png" alt="image-20220323161300277" style="zoom:25%;" /></p>
<p><strong>Node embedding 例子</strong>：</p>
<p>下图是<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1403.6652.pdf"> DeepWalk: Online Learning of Social Representations</a>原图。Karate Club数据集在2D的投影，图中不同颜色的节点在embedding后也是相距比较远的，但同一颜色都是比较近的。(甚至有一种一一对应的映射感觉, 可能效果比较好)</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011921746.png" alt="image-20220323160938534" style="zoom:25%;" /></p>
<h4 id="2-Node-embedding-Encoder-and-Decoder"><a href="#2-Node-embedding-Encoder-and-Decoder" class="headerlink" title="2. Node embedding: Encoder and Decoder"></a>2. Node embedding: Encoder and Decoder</h4><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917024.png" alt="image-20220323162445828" style="zoom:25%;" /></p>
<p><strong>设置</strong></p>
<ul>
<li>假定有一个图G:<ul>
<li><script type="math/tex">\mathbf{V}</script>是顶点集</li>
<li><script type="math/tex">\mathbf{A}</script>是邻接矩阵(假定是二值化的)</li>
<li>为了简单起见，不使用节点特征和额外的信息</li>
</ul>
</li>
</ul>
<h5 id="1-Embedding-Nodes"><a href="#1-Embedding-Nodes" class="headerlink" title="1. Embedding Nodes"></a>1. Embedding Nodes</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917385.png" alt="image-20220323223431397" style="zoom:25%;" /></p>
<p>目标是编码节点，以便embedding space中的相似度近似于图中的相似的。</p>
<p>如上图中，原始的网络中的邻居节点u、v ，编码到embedding空间后，对应的<script type="math/tex">z_\mathbf{u}, z_\mathbf{v}</script>也要相近。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917265.png" alt="image-20220323224409924" style="zoom:25%;" /></p>
<p>节点的相似度计算：</p>
<script type="math/tex; mode=display">
\text{similarity}(u, v) \approx \mathbf{z}_v^T \mathbf{z}_u \tag{1}</script><p>其中, <script type="math/tex">\text{similarity}</script>就是接下来要讲的相似度计算函数，也是这里<script type="math/tex">\text{ENC}</script>表示的编码过程。</p>
<h5 id="2-Learning-Node-Embeddings"><a href="#2-Learning-Node-Embeddings" class="headerlink" title="2. Learning Node Embeddings"></a>2. Learning Node Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011921027.png" alt="image-20220324123920503" style="zoom:25%;" /></p>
<ol>
<li>Encoder 将节点映射到embeddings</li>
<li>定义节点相似度函数(就是一个衡量原始网络中节点相似度的函数，如余弦相似度)</li>
<li>Decoder 记为DEC将embeddings映射为相似度分数</li>
<li>优化encoder参数使得式1成立。</li>
</ol>
<h5 id="3-Two-Key-Components"><a href="#3-Two-Key-Components" class="headerlink" title="3. Two Key Components"></a>3. Two Key Components</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917374.png" alt="image-20220324132755170" style="zoom:25%;" /></p>
<ul>
<li><strong>Encoder</strong>: 映射每个节点到低维度向量。</li>
</ul>
<script type="math/tex; mode=display">
\text{ENC}(v) = \mathbf{z}_v \tag{2}</script><ul>
<li>相似度函数: 明确编码后向量空间和原始网络是怎样的映射关系，如上图，就是原始网络中u和v的相似度和这两个节点embedding后的点积是对应的。</li>
</ul>
<h5 id="4-“Shallow”-Encoding"><a href="#4-“Shallow”-Encoding" class="headerlink" title="4. “Shallow” Encoding"></a>4. “Shallow” Encoding</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917848.png" alt="image-20220324171439630" style="zoom:25%;" /></p>
<p>最简单的编码方法: 编码器仅仅是一个embedding-lookup.</p>
<p>对于式2继续完善下:</p>
<script type="math/tex; mode=display">
\text{ENC}(v) = \mathbf{z}_v = \mathbf{Z} \cdot v\tag{3}</script><p>其中,<script type="math/tex">\mathbf{Z} \in \mathbb{R}^{d\times |\mathcal{V|}}</script>, 这是一个<script type="math/tex">d \times |\mathcal{V}|</script>的矩阵，每一列都是一个节点的embedding[通过学习/优化得到的]。怎么得到后面再说，要明确的是， 这是由<script type="math/tex">d</script>个节点的<script type="math/tex">\mathcal{V}</script>维embedding构成的矩阵。</p>
<p>而<script type="math/tex">v \in \mathbb{I}^{|\mathcal{V}|}</script>是一个指示向量，除了对应节点<script type="math/tex">\mathbf{v}</script>那一列是1外其他都是0（one-hot向量）。这样从矩阵乘法来说，式3相乘的过程就是一个查表的过程。这也是为什么说这是一个embedding-lookup。下图图示就非常清楚了，注意一下这个矩阵<script type="math/tex">\mathbf{Z}</script>名字叫embedding matrix(NLP 同学相对很容易理解)。</p>
<p><strong>学习或优化得到embedding matrix</strong>的<strong>方法</strong>有: <strong>DeepWalk, node2vec</strong>。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917591.png" alt="image-20220324172927542" style="zoom:25%;" /></p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917585.png" alt="image-20220324173143547" style="zoom:25%;" /></p>
<h5 id="5-Framework-Summary"><a href="#5-Framework-Summary" class="headerlink" title="5. Framework Summary"></a>5. Framework Summary</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917053.png" alt="image-20220324173626155" style="zoom:25%;" /></p>
<p><strong>Encoder+Decoder Framework</strong></p>
<ul>
<li>浅层的编码器: embedding lookup</li>
<li>参数优化: <script type="math/tex">\mathbf{Z}</script> 包含<script type="math/tex">u \in \mathbf{V}</script>即图中所有节点embedding  <script type="math/tex">\mathbf{z}_u</script>.</li>
<li>深层的编码器GNNs将会在Lecture 6讲到。</li>
</ul>
<ul>
<li>Decoder：基于节点相似度</li>
<li>目标：最大化相似节点对(u, v)的<script type="math/tex">\mathbf{z}_v^T \mathbf{z}_u</script>.</li>
</ul>
<h5 id="6-How-to-Define-Node-Similarity"><a href="#6-How-to-Define-Node-Similarity" class="headerlink" title="6. How to Define Node Similarity?"></a>6. How to Define Node Similarity?</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917268.png" alt="image-20220324175805592" style="zoom:25%;" /></p>
<ul>
<li>上述方法的关键点是怎么定义<strong>节点相似度</strong> ？</li>
<li>两个节点应该有相似的embedding如果它们…<ul>
<li>是邻接的</li>
<li>有共同邻居节点</li>
<li>有相似的结构特征</li>
</ul>
</li>
<li>接下来将用<strong>随机游走</strong>来学习获得节点相似度，和怎样为该相似度指标优化embedding。</li>
</ul>
<h5 id="7-Note-on-Node-Embeddings"><a href="#7-Note-on-Node-Embeddings" class="headerlink" title="7. Note on Node Embeddings"></a>7. Note on Node Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917006.png" alt="image-20220324180525403" style="zoom:25%;" /></p>
<ul>
<li>监督学习和非监督学习方法都可以用来学习节点的embedding<ul>
<li><strong>不利用</strong>节点标签</li>
<li><strong>不利用</strong>节点特征</li>
<li>目标是直接估计一组节点坐标(embedding)，以便保留网络某些结构</li>
</ul>
</li>
<li>embeddings都是任务无关的<ul>
<li>不为特定任务训练但可以在任何任务上使用</li>
</ul>
</li>
</ul>
<h4 id="3-Random-Walk-Approaches-for-Node-Embeddings"><a href="#3-Random-Walk-Approaches-for-Node-Embeddings" class="headerlink" title="3. Random Walk Approaches for Node Embeddings"></a>3. Random Walk Approaches for Node Embeddings</h4><h5 id="1-Notation"><a href="#1-Notation" class="headerlink" title="1. Notation"></a>1. Notation</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917664.png" alt="image-20220324212650526" style="zoom:25%;" /></p>
<p><strong>记号</strong>：</p>
<ul>
<li>向量<script type="math/tex">\mathbf{z}_u</script>: 节点u的embedding (我们要学习到的)</li>
<li>概率<script type="math/tex">P(\mathcal{v}|\mathbf{z}_u)</script>: 基于<script type="math/tex">\mathbf{z}_u</script>的预测概率，即从节点u开始随机游走到节点v的概率</li>
</ul>
<p><strong>非线性函数用来生成预测概率</strong>：</p>
<ol>
<li><strong>Softmax函数</strong>：将K实数向量转化为总和为1的K概率值，Softmax函数分子就是将原值<script type="math/tex">\mathbf{z}_i</script>转化为e的幂次，分母表示归一化因子来确保和为1</li>
<li><strong>Sigmoid函数</strong>：S-shape函数将实数值转化为(0, 1)之间的值</li>
</ol>
<h5 id="2-Random-Walk"><a href="#2-Random-Walk" class="headerlink" title="2. Random Walk"></a>2. Random Walk</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917475.png" alt="image-20220325000320160" style="zoom:25%;" /></p>
<p>给定一个图和一个起点，我们可以随机选取一个邻居作为下一个游走的点，接下来我们继续选取下一个邻居游走，重复。这个访问的节点随机序列就是<strong>图的随机游走</strong>。</p>
<h5 id="3-Random-Walk-Embeddings"><a href="#3-Random-Walk-Embeddings" class="headerlink" title="3. Random-Walk Embeddings"></a>3. Random-Walk Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917598.png" alt="image-20220325001649371" style="zoom:25%;" /></p>
<p>这里<script type="math/tex">\mathbf{z}_u^T\mathbf{z}_v</script>表示<script type="math/tex">\mathbf{u}, \ \mathbf{v}</script>在图中一次随机游走时共同出现的概率。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917471.png" alt="image-20220325002437153" style="zoom:25%;" /></p>
<ol>
<li>估算使用策略R的随机游走从节点u访问到节点v的概率</li>
<li>这个概率就是节点u和v的相似度，我们可以根据这个概率来优化embedding，在embedding空间的相似度，这里<script type="math/tex">\text{dot product}=\cos(\theta)</script>,就是编码的随机游走相似度。</li>
</ol>
<h5 id="4-Why-Random-Walks"><a href="#4-Why-Random-Walks" class="headerlink" title="4. Why Random Walks?"></a>4. Why Random Walks?</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917195.png" alt="image-20220325003657831" style="zoom:25%;" /></p>
<ul>
<li><strong>可解释性</strong>：灵活的随机的节点相似度定义，随机游走每步的游走表示了节点的局部信息，游走路径序列表示了全局信息，这样包含了局部和高阶的邻域信息。<ul>
<li><strong>想法</strong>:如果以较高的概率随机从节点u访问节点v，那么u和v是相似的(高阶，多跳的信息)。</li>
</ul>
</li>
<li>高效性：不需要在训练时考虑所有节点对；仅仅只要考虑随机游走时的共现对，节省了计算量</li>
</ul>
<h5 id="5-Unsupervised-Feature-Learning"><a href="#5-Unsupervised-Feature-Learning" class="headerlink" title="5. Unsupervised Feature Learning"></a>5. Unsupervised Feature Learning</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917558.png" alt="image-20220325151321054" style="zoom:25%;" /></p>
<ul>
<li><strong>直觉</strong>: 找到节点在保留相似度的d维空间的embedding。</li>
<li><strong>想法</strong>:学习节点的embedding使得网络中邻近的节点的embedding是相近的，就是如果在网络中邻近的节点，embedding后相似度要高，这样就将图结构的网络空间信息embedding到embedding space。</li>
<li>给定节点u，怎么定义邻近节点？<ul>
<li><script type="math/tex">N_R(u)</script>表示某一随机游走策略R中获得的节点u的邻居节点。</li>
</ul>
</li>
</ul>
<h5 id="6-Feature-Learning-as-Optimization"><a href="#6-Feature-Learning-as-Optimization" class="headerlink" title="6. Feature Learning as Optimization"></a>6. Feature Learning as Optimization</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917865.png" alt="image-20220325155505388" style="zoom:25%;" /></p>
<p>如果设置优化问题？</p>
<ul>
<li>给定图<script type="math/tex">G=(V, E)</script></li>
<li>目标是学习一个映射<script type="math/tex">f: u \to \mathbb{R}^d \ : f(u)=\mathbf{z}_u</script></li>
<li>对数似然目标函数：</li>
</ul>
<script type="math/tex; mode=display">
\max_{f} \sum_{u\in V} \log \ P(N_R(u)|\mathbf{Z}_u) \tag{3}</script><p>其中，<script type="math/tex">N_R(u)</script> 是某一策略R随机游走中节点u的邻居节点</p>
<p>解释下式3，对于节点u和其邻居节点，<script type="math/tex">P(N_R(u)|\mathbf{Z}_u)</script>表示给定节点u的情况下，让其邻居节点出现的概率最大。总的来说就是让图中所有节点，在映射函数f的作用下，使得每个节点u的邻居节点出现的概率的对数和最大。</p>
<ul>
<li>给定节点u，我们希望学习特征表示是对出现节点u随机游走邻域节点<script type="math/tex">N_R(u)</script>的预测。</li>
</ul>
<h5 id="7-Random-Walk-Optimization"><a href="#7-Random-Walk-Optimization" class="headerlink" title="7. Random Walk Optimization"></a>7. Random Walk Optimization</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917469.png" alt="image-20220325172104022" style="zoom:25%;" /></p>
<p><strong>怎么去做？</strong></p>
<ol>
<li>使用固定长度的游走策略R从图中每个节点u进行随机游走</li>
<li>对每个节点u记录其<script type="math/tex">N_R(u)</script>，就是从u出发随机游走得到的节点集合(这是个multiset，因为有重复元素,随机游走会重复访问多次)</li>
<li>按照给定节点u预测其邻域节点<script type="math/tex">N_R(u)</script></li>
</ol>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917625.png" alt="image-20220325173006647" style="zoom:25%;" /></p>
<p>等价地，</p>
<script type="math/tex; mode=display">
\mathcal{L} = \sum_{u \in V} \sum_{v \in N_R(u)} - \log (P(v|\mathbf{z}_u)) \tag{4}</script><p>这里把<script type="math/tex">N_R(u)</script>用v来表示了下。</p>
<ul>
<li><strong>直觉</strong>: 优化embeddings <script type="math/tex">\mathbf{z}_u</script>来最大随机游走共现的似然概率。</li>
<li>对<script type="math/tex">P(v|\mathbf{z}_u)</script>使用softmax有：</li>
</ul>
<script type="math/tex; mode=display">
P(v|\mathbf{z}_u) = \frac{\exp(\mathbf{z}_u^T\mathbf{z}_v)}{\sum_{n\in V} \exp(\mathbf{z}_u^T\mathbf{z}_n)} \tag{5}</script><p>为什么使用softmax? 因为节点v的和节点u相似度最大的，经过<script type="math/tex">f(x) = e^x</script>处理后能更加区分出来。分母只是因为要归一化，概率和为1。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011917730.png" alt="image-20220325174228884" style="zoom:25%;" /></p>
<p>将式4和式5<strong>结合起来</strong>：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \sum_{u \in V} \sum_{v \in N_R(u)} - \log (\frac{\exp(\mathbf{z}_u^T\mathbf{z}_v)}{\sum_{n\in V }  \exp(\mathbf{z}_u^T\mathbf{z}_n)}) \tag{6}</script><ol>
<li>第一个求和是对图中所有节点u，要整体最大不能是单一节点</li>
<li>第二个求和是对从u到v的所有随机游走中出现的节点v求和</li>
<li>最后黄色部分是预测在随机游走中u和v共现的概率</li>
</ol>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918028.png" alt="image-20220325174939286" style="zoom:25%;" /></p>
<p>但实际做起来计算代价非常高，是图节点数的平方次复杂度。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918101.png" alt="image-20220325175101141" style="zoom:25%;" /></p>
<p>那么我们能不能优化式6呢？</p>
<p>分母的归一化部分，有<script type="math/tex">|V|</script>的复杂度，如果能优化就会极大降低计算复杂度。</p>
<h5 id="8-Negative-Sampling"><a href="#8-Negative-Sampling" class="headerlink" title="8.Negative Sampling"></a>8.Negative Sampling</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918820.png" alt="image-20220325180542372" style="zoom:25%;" /></p>
<p><strong>解决方法</strong>： 负采样。</p>
<p>这里将softmax替换为sigmoid, 近似得到:</p>
<script type="math/tex; mode=display">
\log (\frac{\exp(\mathbf{z}_u^T\mathbf{z}_v)}{\sum_{n\in V }  \exp(\mathbf{z}_u^T\mathbf{z}_n)})
\approx \log(\sigma(\mathbf{z}_u^T\mathbf{z}_v)) - \sum_{i=1}^k \log(\mathbf{z}_u^T\mathbf{z}_{n_i})),\  其中\ n_i \sim P_V
\tag{7}</script><p>负采样就是将式7分母归一化部分中所有节点<script type="math/tex">n</script>替换为，随机采样得到的k个<strong>负样本</strong><script type="math/tex">n_i</script>，即不在random walk上的样本。</p>
<p>负采样使得对数部分计算非常迅速。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918818.png" alt="image-20220325212208362" style="zoom:25%;" /></p>
<ul>
<li>以节点度对应的概率来采样k个负样本节点</li>
<li>两个决定k的因素<ol>
<li>更高的k对应更可靠的估计值</li>
<li>更高的k对应着更多的负样本带来的更高的偏差</li>
</ol>
</li>
</ul>
<p>实际上,<script type="math/tex">k=5-20</script>。那么能不能采样任何节点获取负样本，或者只采样不在random walk上的节点？</p>
<p>答案是：实际操作中，对任何节点采样来获得负样本，高效性。正确的方式是只采样不在random wall上的节点。</p>
<h5 id="9-Stochastic-Gradient-Descent"><a href="#9-Stochastic-Gradient-Descent" class="headerlink" title="9. Stochastic Gradient Descent"></a>9. Stochastic Gradient Descent</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918531.png" alt="image-20220325220304225" style="zoom:25%;" /></p>
<ul>
<li>获得目标函数后，我们怎么最小化它呢？</li>
<li>梯度下降来最小化损失函数<script type="math/tex">\mathcal{L}</script>:<ul>
<li>在所有节点u中随机选取一个初始化，得到<script type="math/tex">\mathbf{z}_u</script></li>
<li>迭代直到收敛<ul>
<li>对所有节点u，计算导数<script type="math/tex">\frac{\partial \mathcal{L}}{\partial \mathbf{z}_u}</script></li>
<li>对所有节点u，计算以学习率为<script type="math/tex">\eta</script>更新迭代后的导数: <script type="math/tex">\mathbf{z}_u \leftarrow \mathbf{z}_u - \eta \frac{\partial \mathcal{L}}{\partial \mathcal{z}_u}</script></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918634.png" alt="image-20220325223809441" style="zoom:25%;" /></p>
<p><strong>Stochastic Gradient Descent</strong> 随机梯度下降就是把所有节点替换为一批独立的训练样本节点。</p>
<h5 id="10-Random-Walks-Summary"><a href="#10-Random-Walks-Summary" class="headerlink" title="10. Random Walks: Summary"></a>10. Random Walks: Summary</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918522.png" alt="image-20220325224026963" style="zoom:25%;" /></p>
<ol>
<li>从图中每一个节点进行短径固定长度的随机游走</li>
<li>对每一个节点u记录其邻域节点<script type="math/tex">N_R(u)</script>， 这是一个从u开始随机游走得到节点的multiset，有重复节点</li>
<li>使用随机梯度下降算法来优化embedding，使得损失函数最小</li>
</ol>
<h5 id="11-How-should-we-randomly-walk？"><a href="#11-How-should-we-randomly-walk？" class="headerlink" title="11. How should we randomly walk？"></a>11. How should we randomly walk？</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918826.png" alt="image-20220325224527820" style="zoom:25%;" /></p>
<ul>
<li><p>前面已经讲了怎么在给定策略R的情况下优化embeddings</p>
</li>
<li><p>那么我们应该使用什么策略进行随机游走呢？最简单的想法：直接固定长度，每个节点都无偏的随机游走。</p>
<p>但问题是这样的策略使得相似度有非常大的局限性。</p>
</li>
<li><p>我们怎么将其泛化呢？</p>
</li>
</ul>
<h5 id="12-Node2Vec"><a href="#12-Node2Vec" class="headerlink" title="12. Node2Vec"></a>12. Node2Vec</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918658.png" alt="image-20220325225110352" style="zoom:25%;" /></p>
<ol>
<li><strong>Overview of node2vec</strong></li>
</ol>
<p>node2vec 来自于论文 <a target="_blank" rel="noopener" href="https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf">node2vec: Scalable Feature Learning for Networks</a>，想详细了解可以阅读下。</p>
<ul>
<li>目标： 在特征空间嵌入相似性来表示邻近节点</li>
<li>将这个目标表示为最大似然优化问题，对下游预测任务独立。</li>
<li><p>关键点：节点u的邻域节点<script type="math/tex">N_R(u)</script>灵活性能丰富的节点embeddings</p>
</li>
<li><p>进一步的有偏的2阶(2阶就是走2步)随机游走R可以生成节点u的邻域节点<script type="math/tex">N_R(u)</script>的邻近节点</p>
</li>
</ul>
<ol>
<li><strong>node2vec: Bias Walks</strong></li>
</ol>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918692.png" alt="image-20220325235431558" style="zoom:25%;" /></p>
<p><strong>想法</strong>：使用灵活，有偏的随机游走能平衡网络局部和全局信息。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011921819.png" alt="image-20220326001102908" style="zoom:25%;" /></p>
<p>两种典型的策略来定义给定节点u的邻域节点<script type="math/tex">N_R(u)</script>:BFS 和DFS。</p>
<p>这是两种常见的图搜索算法，</p>
<ul>
<li><strong>BFS广度优先搜索</strong>: 以某节点为起点搜索其所有的邻居节点，局部视角</li>
<li>DFS<strong>深度优先搜索</strong>: 以某节点为起点直到搜索到终点为止，全局视角</li>
</ul>
<p>下图是二者比较：</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918472.png" alt="image-20220326002815491" style="zoom:25%;" /></p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918555.png" alt="202203260030604" style="zoom:25%;" /></p>
<p><strong>插入BFS和DFS</strong>：</p>
<p>有偏的固定长度随机游走R，在给定节点u的情况下能得到邻域节点<script type="math/tex">N_R(u)</script></p>
<ul>
<li>两个超参数<ol>
<li><strong>Return parameter p(返回参数)</strong>，用来控制是否返回以前的节点。</li>
<li><strong>In-out parameter q(出入参数)</strong>, 表示在起点附近游走inwards（类似BFS）和向更远处游走outwards（类似DFS）的比例，直觉来说就是BFS和DFS的比率。</li>
</ol>
</li>
</ul>
<h5 id="13-Biased-Random-Walks"><a href="#13-Biased-Random-Walks" class="headerlink" title="13. Biased Random Walks"></a>13. Biased Random Walks</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918289.png" alt="image-20220326195545312" style="zoom:25%;" /></p>
<p><strong>有偏的2阶随机游走探索网络邻居节点：</strong></p>
<ul>
<li>假设通过边<script type="math/tex">(s_1, w)</script>到达w节点</li>
<li>那么现在w节点的邻居节点可能是<script type="math/tex">s1, s2, s_3</script>。这跟最开始的起点<script type="math/tex">s_1</script>的意义是不一样的，具体如上图所示。</li>
</ul>
<p><strong>想法</strong>：记住从哪来</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918457.png" alt="image-20220326203131058" style="zoom: 25%;" /></p>
<ul>
<li><p>通过边<script type="math/tex">(s_1, w)</script>走到w节点，下一步去哪？</p>
<p>这里，如上图所示，走到下一个节点的的概率是不一样的。(注意，<script type="math/tex">\frac{1}{p}, \frac{1}{q}, 1</script>不是归一化的概率，加起来和不为1)</p>
</li>
<li><p>p, q是 模型的转移概率。</p>
</li>
</ul>
<p>如上图所示，前一步通过边<script type="math/tex">(s_1, w)</script>到达节点w。现在走到的节点w，邻居节点有<script type="math/tex">s_1, s_2, s_3, s_4</script>。具体怎么设计p, q概率呢？</p>
<p>根据上一跳节点和下一跳节点的距离设计，说到距离，就要明确这两点在哪？上一跳节点为<script type="math/tex">s_1</script>，下一跳为<script type="math/tex">s_1, s_2, s_3, s_4</script>。</p>
<p>论文 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.00653.pdf">node2vec: Scalable Feature Learning for Networks</a> <strong>3.2.2 Search bias α</strong>部分提到：</p>
<script type="math/tex; mode=display">
\alpha_{p q}(t, x)=\left\{\begin{array}{ll}
\frac{1}{p} & \text { if } d_{t x}=0 \\
1 & \text { if } d_{t x}=1 \\
\frac{1}{q} & \text { if } d_{t x}=2
\end{array}\right. \tag{7}</script><p>这里<script type="math/tex">t, x</script>分别表示上一跳节点，和未来要走到的节点。<script type="math/tex">d_{tx}</script>表示距离。</p>
<p>上图中，<script type="math/tex">s_1</script>到<script type="math/tex">s_1</script>的距离为0，所以为<script type="math/tex">\frac{1}{p}</script>。</p>
<p>还有可能跳到节点<script type="math/tex">s_2, s_2, s_3</script>到<script type="math/tex">s_1</script>的距离分别为1， 2， 2，就得到如图示的转移概率。这时的概率还没有归一化，最后要归一化。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919246.png" alt="image-20220326214838642" style="zoom:25%;" /></p>
<ul>
<li>类似BFS的游走：较小的p值，那么<script type="math/tex">\frac{1}{p}</script>就较大，会回到上一跳节点。</li>
<li>类似DFS的游走: 较小的q值，会往跟上一跳较远的距离跳</li>
</ul>
<h5 id="14-node2vec-algorithm"><a href="#14-node2vec-algorithm" class="headerlink" title="14. node2vec algorithm"></a>14. node2vec algorithm</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919805.png" alt="image-20220326215424958" style="zoom:25%;" /></p>
<ol>
<li>计算随机游走概率</li>
<li>从每个节点u开始模拟策略r距离为l的随机游走</li>
<li>用随机梯度下降优化node2vec 目标</li>
</ol>
<p>优点：线性时间复杂度(节点邻居树是固定的)，三步都是独立的可以并行化。</p>
<p>其它随机游走想法：</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919721.png" alt="image-20220326220933815" style="zoom:25%;" /></p>
<h5 id="15-Summary-so-far"><a href="#15-Summary-so-far" class="headerlink" title="15. Summary so far"></a>15. Summary so far</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919112.png" alt="image-20220326221024967" style="zoom:25%;" /></p>
<ul>
<li>核心想法： 嵌入节点使得<strong>嵌入空间的距离</strong>反映<strong>原网络的节点相似度</strong></li>
<li>不同的节点相似度表示<ul>
<li>简单的： 如果两个节点相连就相似</li>
<li>邻居的重叠度(第二节谈到)</li>
<li>随机游走方法(本节内容)</li>
</ul>
</li>
</ul>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919306.png" alt="image-20220326221609150" style="zoom:25%;" /></p>
<p>那我们应该用什么方法？</p>
<ul>
<li>没有一种方法是万能的，如node2vec在节点分类表现好，然而其他方法在边预测上好</li>
<li>随机游走方法通常比较高效</li>
<li>总的来说，要选择节点相似度符合你的任务。</li>
</ul>
<h4 id="4-Embedding-Entire-Graphs"><a href="#4-Embedding-Entire-Graphs" class="headerlink" title="4. Embedding Entire Graphs"></a>4. Embedding Entire Graphs</h4><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919374.png" alt="image-20220326223331824" style="zoom:25%;" /></p>
<ul>
<li>目标：想要把一个子图或者一张图嵌入到特征空间去，得到图的embedding:<script type="math/tex">\mathbf{z}_G</script></li>
<li>具体任务：<ul>
<li>对有毒和无毒分子分类</li>
<li>鉴别异常的图</li>
</ul>
</li>
</ul>
<h5 id="1-方法1"><a href="#1-方法1" class="headerlink" title="1. 方法1"></a>1. 方法1</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919683.png" alt="image-20220326225911614" style="zoom:25%;" /></p>
<p><strong>简单但有效的方法1</strong>：</p>
<ol>
<li>对子图和整张图进行标准的node embedding</li>
<li>然后对图(或子图)中所有节点的embedding直接求和平均：</li>
</ol>
<script type="math/tex; mode=display">
\mathbf{z}_G = \sum_{v \in G} \mathbf{z}_v \tag{8}</script><h5 id="2-方法2"><a href="#2-方法2" class="headerlink" title="2. 方法2"></a>2. 方法2</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919837.png" alt="image-20220326232345958" style="zoom:25%;" /></p>
<p>方法2：引入一个”虚拟节点“来表示子图，然后再对其用node embedding。</p>
<h5 id="3-方法3：-Anonymous-Walk-Embeddings"><a href="#3-方法3：-Anonymous-Walk-Embeddings" class="headerlink" title="3. 方法3： Anonymous Walk Embeddings"></a>3. 方法3： Anonymous Walk Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919689.png" alt="image-20220326232624070" style="zoom:25%;" /></p>
<p>来源于 论文<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.11921.pdf">Anonymous Walk Embeddings</a>。</p>
<blockquote>
<p>匿名游走的节点如果在先前出现过，则将此时的index设置为它第一次出现时的index，习惯性从1开始计数，每当遇到一个新的没有遇到过的节点，则自增state（index），即state的最大值等于这一条walk中存在的unique的节点数目。</p>
<p>​                                                                                                                                                        —— <a target="_blank" rel="noopener" href="https://blog.csdn.net/pku_langzi/article/details/121797407">Machine Learning with Graphs 之 Anonymous Walk Embeddings</a></p>
</blockquote>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011921546.png" alt="image-20220326233623495" style="zoom:25%;" /></p>
<p>对于例子：Random walk <script type="math/tex">w_1</script>整条walk的序列为<script type="math/tex">1 \to 2 \to 3 \to 2\to 3</script>.</p>
<p>而Random walk <script type="math/tex">w_2</script>的序列为<script type="math/tex">1\to 2\to 3\to 2\to 3</script>。它们有一样的anonymous walk.</p>
<h5 id="4-Number-of-Walks-Grows"><a href="#4-Number-of-Walks-Grows" class="headerlink" title="4. Number of Walks Grows"></a>4. Number of Walks Grows</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011920667.png" alt="image-20220326235135712" style="zoom:25%;" /></p>
<p>对于一个给定的图G，匿名游走得到的pattern数目跟路径长度l成指数成长。</p>
<p>路径长度为3的匿名游走pattern有5个。</p>
<h5 id="5-Simple-Use-of-Anonymous-Walks"><a href="#5-Simple-Use-of-Anonymous-Walks" class="headerlink" title="5. Simple Use of Anonymous Walks"></a>5. Simple Use of Anonymous Walks</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919572.png" alt="image-20220327001544263" style="zoom:25%;" /></p>
<p>那么我们怎么利用匿名游走来嵌入整张图呢？</p>
<ul>
<li>记录所有的长度l的匿名游走<script type="math/tex">w_i</script></li>
<li>将图表示为这些匿名游走的分布</li>
</ul>
<p>具体来说，就像上节中的Graphlet Degree Vector(GDV)，我们先统计得到所有长度为l的匿名游走pattern，然后将图表示为获得pattern的频数或者概率。</p>
<p>举例来说,</p>
<ol>
<li>设定l=3</li>
<li>将图表示为5维的向量<ul>
<li>因为长度为3的匿名游走有5种pattern</li>
<li><script type="math/tex">\mathbf{z}_G[i]=</script> 图中出现匿名游走pattern i的概率.</li>
</ul>
</li>
</ol>
<h5 id="6-Sampling-Anonymous-Walks"><a href="#6-Sampling-Anonymous-Walks" class="headerlink" title="6. Sampling Anonymous Walks"></a>6. Sampling Anonymous Walks</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919786.png" alt="image-20220327003147367" style="zoom:25%;" /></p>
<p>当l=12时，匿名游走w数目有4M。实际操作中，我们用采样来降低计算复杂度。</p>
<ul>
<li>独立地采样m条<strong>随机游走</strong>路径来近似<strong>匿名游走</strong>pattern</li>
<li>用这些采样得到的随机游走路径的概率分布来表示图</li>
</ul>
<p>那么我们的m取多大？可用下式来估算：</p>
<script type="math/tex; mode=display">
m=\left[\frac{2}{\varepsilon^{2}}\left(\log \left(2^{\eta}-2\right)-\log (\delta)\right)\right] \tag{9}</script><p>其中，<script type="math/tex">\eta</script>是长度为<script type="math/tex">l</script>的匿名游走的总数。计算下上图例子，</p>
<p>当<script type="math/tex">\epsilon = 0.1, \delta=0.01</script>时,  <script type="math/tex">m = 200 \times 612.5=122,500</script></p>
<h5 id="7-New-idea-Learn-Walk-Embeddings"><a href="#7-New-idea-Learn-Walk-Embeddings" class="headerlink" title="7. New idea: Learn Walk Embeddings"></a>7. New idea: Learn Walk Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919522.png" alt="image-20220327005327087" style="zoom:25%;" /></p>
<p>不简单地用每次游走出现的次数的分数来表示匿名游走<script type="math/tex">w_i</script>,而是学习匿名游走<script type="math/tex">w_i</script>的embedding <script type="math/tex">\mathbf{z}</script>。</p>
<p>具体来说，(这跟NLP的doc2vec类似，后面再说)</p>
<ul>
<li>就是将所有的匿名游走的embedding <script type="math/tex">\mathbf{z}_i</script>加上图的embedding <script type="math/tex">\mathbf{z}_G</script>一起输入学习，其中<script type="math/tex">\mathbf{Z}={\mathbf{z}_i: i=1 \cdots\eta}</script>。</li>
</ul>
<p>这里，<script type="math/tex">\eta</script> 是采样的匿名游走数目。</p>
<p><strong>那么怎么embed walks？</strong></p>
<ul>
<li><strong>想法</strong>：跟node2vec类似，通过预测下一跳周围的walk来学习embed walks。</li>
</ul>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919585.png" alt="image-20220327115103172" style="zoom:25%;" /></p>
<p><strong>实际流程如下</strong>：</p>
<ul>
<li>输出：也就是预测，输入图的embeding <script type="math/tex">\mathbf{z}_G</script> 。这个<script type="math/tex">\mathbf{z}_G</script> 也是要学习的目标。</li>
<li>从节点1开始，采样获得匿名随机游走，如上图所示<script type="math/tex">w_1, w_2, w_3, w_4</script>。</li>
<li>学习预测 walks 共现在<script type="math/tex">\Delta-\text{size}</script>窗口内的概率，比如，当窗口为2时，给定<script type="math/tex">w_1, w_2</script>去预测<script type="math/tex">w_3</script></li>
</ul>
<p>这样整个目标函数为：</p>
<script type="math/tex; mode=display">
\max_{\mathbf{z}_G } \sum_{t=\Delta+1}^T \log P(w_t| w_{t-\Delta}, \cdots, w_{t-1}, \mathbf{z}_G) \tag{10}</script><p>其中，<script type="math/tex">T</script>是所有的walks数目。</p>
<p>对于式10，</p>
<ul>
<li>对数里面，表示给定<strong>图</strong>的embedding <script type="math/tex">\mathbf{z}_G</script> 和一定范围窗口内的<strong>采样匿名随机游走</strong>情况下，下一个walk出现的概率。</li>
</ul>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011919364.png" alt="image-20220327122634050" style="zoom:25%;" /></p>
<p>每个步骤具体来说，</p>
<ul>
<li>从节点u获取长度为l的T条不同的随机walks</li>
<li>学习预测将会出现在共现<script type="math/tex">\Delta-\text{size}</script>窗口内的walks</li>
<li>评估匿名游走<script type="math/tex">w_i</script>的embedding <script type="math/tex">\mathbf{z}_i</script>。</li>
</ul>
<p>目标函数为：</p>
<script type="math/tex; mode=display">
\max _{\mathbf{z}_{i}, \mathbf{z}_{\boldsymbol{G}}} \frac{1}{T} \sum_{t=\Delta}^{T} \log P\left(w_{t} \mid\left\{w_{t-\Delta}, \ldots, w_{t-1}, \mathbf{z}_{\boldsymbol{G}}\right\}\right) \tag{11}</script><p>这里，<script type="math/tex">\mathbf{z}_{i}</script>是负采样得到所有匿名游走的embedding，<script type="math/tex">\mathbf{z}_{\boldsymbol{G}}</script>是图的embedding.</p>
<script type="math/tex; mode=display">
P\left(w_{t} \mid\left\{w_{t-\Delta}, \ldots, w_{t-1}, \mathbf{z}_{\boldsymbol{G}}\right\}\right) =\frac{\exp(y(w_t))}{\sum^{\Delta}_{i=1}\exp(y(w_i))} \tag{12}</script><p>式12，表示当前walk t共现的可能性，分母是归一化因子，为了确保概率和为1。</p>
<p>其中<script type="math/tex">y(w_t)</script>计算如下：</p>
<script type="math/tex; mode=display">
y(w_t) = b+U \cdot (\text{cat}(\frac{1}{\Delta}\sum_{i=1}^\Delta \mathbf{z}_i, \mathbf{z}_\boldsymbol{G})) \tag{13}</script><p>其中，<script type="math/tex">\text{cat}(\frac{1}{\Delta}\sum_{i=1}^\Delta \mathbf{z}_i, \mathbf{z}_\boldsymbol{G})</script>表示：</p>
<ul>
<li>将所有匿名walk的embedding加起来再求平均，从<script type="math/tex">t-\Delta</script>到<script type="math/tex">t-1</script>总共<script type="math/tex">\Delta</script>个embeddings，就除以<script type="math/tex">\Delta</script></li>
<li>然后将平均的embeddings和图的embedding <script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>拼接起来</li>
</ul>
<p>拼接后的embeddings一起输入到一个线性投影层，这就是整个式13的意义。</p>
<p>这里，<script type="math/tex">b \in \mathbb{R}, U\in \mathbb{R}^D</script>是可学习的参数。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918384.png" alt="image-20220327133811721" style="zoom:25%;" /></p>
<p><strong>Optimization：</strong></p>
<ul>
<li>通过优化可以学习到图的embedding <script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>表示<ul>
<li><script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>是不是简单地对walk embedding <script type="math/tex">\mathbf{z}_i</script>求和？<script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>是不是下一个<script type="math/tex">\mathbf{z}_i</script>的残差？</li>
<li>论文中，<script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>是一个独立优化的向量参数，跟<script type="math/tex">\mathbf{z}_i</script>一样</li>
</ul>
</li>
<li>用<script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>来做预测，如图分类。<ul>
<li>选择1： 内积和<script type="math/tex">\mathbf{z}_\boldsymbol{G_1}^T\mathbf{z}_\boldsymbol{G_2}</script>(小节2中提到的)</li>
<li>选择2：把<script type="math/tex">\mathbf{z}_\boldsymbol{G}</script>输入到神经网络来对图分类</li>
</ul>
</li>
</ul>
<p>接下来看看Anonymous Walk Embeddings 跟 doc2vec(来自 <a target="_blank" rel="noopener" href="https://cs.stanford.edu/~quocle/paragraph_vector.pdf">Distributed Representations of Sentences and Documents</a>)类似之处。</p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918847.png" alt="image-20220327135053181" style="zoom:25%;" /></p>
<p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918125.png" alt="image-20220327135156697" style="zoom:35%;" /></p>
<p>比较两幅整体结构图，</p>
<ul>
<li>Graph类似paragraph或document</li>
<li>Anonymous walk类似于 word</li>
</ul>
<p>更多展开分析就不进行了(如公式)，只是说下很多研究都是借鉴前人或其它方向的思想。</p>
<h5 id="8-Summary"><a href="#8-Summary" class="headerlink" title="8. Summary"></a>8. Summary</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011920255.png" alt="image-20220327135800593" style="zoom:25%;" /></p>
<p>总结：</p>
<p>3种graph embedding方法：</p>
<ol>
<li>方法一：简单粗暴直接embed node求和平均它们</li>
<li>方法2：创建super-node映射子图，然后embed 这个super-node</li>
<li>方法3： Anonymous Walk Embeddings</li>
</ol>
<h5 id="9-Preview-Hierarchical-Embeddings"><a href="#9-Preview-Hierarchical-Embeddings" class="headerlink" title="9. Preview:Hierarchical Embeddings"></a>9. Preview:Hierarchical Embeddings</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011924347.png" alt="image-20220327140224220" style="zoom:25%;" /></p>
<ul>
<li>Lecture 8 将学习更先进的方法来获取graph embeddings</li>
<li>在图中使用层次聚类节点，然后对这些聚类进行求和/平均得到节点embeddings</li>
</ul>
<h5 id="10-How-to-Use-Embeddings"><a href="#10-How-to-Use-Embeddings" class="headerlink" title="10. How to Use Embeddings?"></a>10. How to Use Embeddings?</h5><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011924967.png" alt="image-20220327140607370" style="zoom:25%;" /></p>
<p>怎么使用节点的embeddings <script type="math/tex">\mathbf{z}_i</script>：</p>
<ul>
<li>聚类/社区发现: 聚类<script type="math/tex">\mathbf{z}_i</script>点</li>
<li>节点分类：基于<script type="math/tex">\mathbf{z}_i</script>预测节点i的标签</li>
<li>边预测： 基于<script type="math/tex">(\mathbf{z}_i, \mathbf{z}_j)</script>预测边<script type="math/tex">(i, j)</script>, 可以通过平均，平均，哈达玛积(Hadamard), 求embeddings的差值</li>
<li>图预测：通过聚合节点embeddings或匿名随机游走获得的图embedding <script type="math/tex">\mathbf{z}_G</script>来预测图的标签</li>
</ul>
<h4 id="本节总结"><a href="#本节总结" class="headerlink" title="本节总结"></a>本节总结</h4><p><img src="https://aigonna.oss-cn-shenzhen.aliyuncs.com/blog/202205011918804.png" alt="image-20220327140726056" style="zoom:25%;" /></p>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><p>[1] <a target="_blank" rel="noopener" href="https://wandb.ai/syllogismos/machine-learning-with-graphs/reports/7-Graph-Representation-Learning--VmlldzozNzcwMDk">7.Graph Representation Learning</a></p>
<p>[2] <a target="_blank" rel="noopener" href="https://snap-stanford.github.io/cs224w-notes/machine-learning-with-networks/node-representation-learning">Node Representation Learning</a></p>
<p>[3] <a target="_blank" rel="noopener" href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part1-embeddings.pdf">Embeddings</a></p>
<p>[4] <a target="_blank" rel="noopener" href="https://chhzh123.github.io/blogs/2020-02-06-graph-embedding/">图表示学习（1）- 图嵌入</a></p>
<p>[5] [图嵌入 (Graph Embedding) 和图神经网络 (Graph Neural Network)](</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">aigonna</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://aigonna.com/2022/03/03/CS224W_3.%20Node%20Embeddings/">http://aigonna.com/2022/03/03/CS224W_3. Node Embeddings/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://aigonna.com" target="_blank">aigonna</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CS224W/">CS224W</a><a class="post-meta__tags" href="/tags/Node-embedding/">Node embedding</a><a class="post-meta__tags" href="/tags/DeepWalk/">DeepWalk</a><a class="post-meta__tags" href="/tags/node2vec/">node2vec</a><a class="post-meta__tags" href="/tags/Random-Walk/">Random Walk</a><a class="post-meta__tags" href="/tags/Random-Walk-Embeddings/">Random-Walk Embeddings</a><a class="post-meta__tags" href="/tags/Negative-Sampling/">Negative Sampling</a><a class="post-meta__tags" href="/tags/Biased-Random-Walks/">Biased Random Walks</a><a class="post-meta__tags" href="/tags/Anonymous-Walk-Embeddings/">Anonymous Walk Embeddings</a></div><div class="post_share"><div class="social-share" data-image="/img/imgs/14.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://fastly.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/02/27/CS224W_2.%20Traditional%20Methods%20for%20ML%20on%20Graphs/"><img class="next-cover" src="/img/imgs/10.jpg" onerror="onerror=null;src='/img/imgs/0.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">CS224W 2. Traditional Methods for ML on Graphs</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/27/CS224W_2. Traditional Methods for ML on Graphs/" title="CS224W 2. Traditional Methods for ML on Graphs"><img class="cover" src="/img/imgs/10.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-27</div><div class="title">CS224W 2. Traditional Methods for ML on Graphs</div></div></a></div><div><a href="/2022/02/12/CS224W_1. Introduction Machine Learning for Graphs/" title="1. Introduction Machine Learning for Graphs"><img class="cover" src="/img/imgs/9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-12</div><div class="title">1. Introduction Machine Learning for Graphs</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="lv-container" data-id="city" data-uid="MTAyMC81MDc2My8yNzI0NQ"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Node-Embeddings"><span class="toc-text">3. Node Embeddings</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Recap-Traditioal-ML-for-Graphs"><span class="toc-text">1. Recap: Traditioal ML for Graphs</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-Graph-representation-learning"><span class="toc-text">1. Graph representation learning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-Why-Embedding%EF%BC%9F"><span class="toc-text">2. Why Embedding？</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Node-embedding-Encoder-and-Decoder"><span class="toc-text">2. Node embedding: Encoder and Decoder</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-Embedding-Nodes"><span class="toc-text">1. Embedding Nodes</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-Learning-Node-Embeddings"><span class="toc-text">2. Learning Node Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-Two-Key-Components"><span class="toc-text">3. Two Key Components</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E2%80%9CShallow%E2%80%9D-Encoding"><span class="toc-text">4. “Shallow” Encoding</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-Framework-Summary"><span class="toc-text">5. Framework Summary</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-How-to-Define-Node-Similarity"><span class="toc-text">6. How to Define Node Similarity?</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-Note-on-Node-Embeddings"><span class="toc-text">7. Note on Node Embeddings</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Random-Walk-Approaches-for-Node-Embeddings"><span class="toc-text">3. Random Walk Approaches for Node Embeddings</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-Notation"><span class="toc-text">1. Notation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-Random-Walk"><span class="toc-text">2. Random Walk</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-Random-Walk-Embeddings"><span class="toc-text">3. Random-Walk Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-Why-Random-Walks"><span class="toc-text">4. Why Random Walks?</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-Unsupervised-Feature-Learning"><span class="toc-text">5. Unsupervised Feature Learning</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-Feature-Learning-as-Optimization"><span class="toc-text">6. Feature Learning as Optimization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-Random-Walk-Optimization"><span class="toc-text">7. Random Walk Optimization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-Negative-Sampling"><span class="toc-text">8.Negative Sampling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-Stochastic-Gradient-Descent"><span class="toc-text">9. Stochastic Gradient Descent</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-Random-Walks-Summary"><span class="toc-text">10. Random Walks: Summary</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#11-How-should-we-randomly-walk%EF%BC%9F"><span class="toc-text">11. How should we randomly walk？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#12-Node2Vec"><span class="toc-text">12. Node2Vec</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#13-Biased-Random-Walks"><span class="toc-text">13. Biased Random Walks</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#14-node2vec-algorithm"><span class="toc-text">14. node2vec algorithm</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#15-Summary-so-far"><span class="toc-text">15. Summary so far</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Embedding-Entire-Graphs"><span class="toc-text">4. Embedding Entire Graphs</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%96%B9%E6%B3%951"><span class="toc-text">1. 方法1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%96%B9%E6%B3%952"><span class="toc-text">2. 方法2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%96%B9%E6%B3%953%EF%BC%9A-Anonymous-Walk-Embeddings"><span class="toc-text">3. 方法3： Anonymous Walk Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-Number-of-Walks-Grows"><span class="toc-text">4. Number of Walks Grows</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-Simple-Use-of-Anonymous-Walks"><span class="toc-text">5. Simple Use of Anonymous Walks</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-Sampling-Anonymous-Walks"><span class="toc-text">6. Sampling Anonymous Walks</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-New-idea-Learn-Walk-Embeddings"><span class="toc-text">7. New idea: Learn Walk Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-Summary"><span class="toc-text">8. Summary</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-Preview-Hierarchical-Embeddings"><span class="toc-text">9. Preview:Hierarchical Embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#10-How-to-Use-Embeddings"><span class="toc-text">10. How to Use Embeddings?</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AC%E8%8A%82%E6%80%BB%E7%BB%93"><span class="toc-text">本节总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inference"><span class="toc-text">Inference</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023&nbsp;<i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;"class="fas fa-heart"></i> By aigonna</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://fastly.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      //tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://fastly.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'forest',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadLivere () {
  if (typeof LivereTower === 'object') {
    window.LivereTower.init()
  }
  else {
    (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
    })(document, 'script');
  }
}

if ('Livere' === 'Livere' || !false) {
  if (false) btf.loadComment(document.getElementById('lv-container'), loadLivere)
  else loadLivere()
}
else {
  function loadOtherComment () {
    loadLivere()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>
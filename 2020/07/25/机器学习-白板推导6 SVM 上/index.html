<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习-白板推导6 SVM 上 | aigonna</title><meta name="keywords" content="SVM,硬间隔,软间隔,对偶问题"><meta name="author" content="aigonna"><meta name="copyright" content="aigonna"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="机器学习-白板推导6 SVM 上1.SVM 核心知识点Support Vector Machine(SVM) 有三宝，间隔，对偶，核技巧。其分类有：  Hard-margin SVM  Soft-margin SVM  Kernel SVM  本文将介绍软硬间隔部分, 核技巧等将在下篇中介绍。 2. SVM模型引入 SVM模型就是找到一个超平面将两类数据点分隔开，这个超平面记为f(\boldsym">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-白板推导6 SVM 上">
<meta property="og:url" content="http://aigonna.com/2020/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC6%20SVM%20%E4%B8%8A/index.html">
<meta property="og:site_name" content="aigonna">
<meta property="og:description" content="机器学习-白板推导6 SVM 上1.SVM 核心知识点Support Vector Machine(SVM) 有三宝，间隔，对偶，核技巧。其分类有：  Hard-margin SVM  Soft-margin SVM  Kernel SVM  本文将介绍软硬间隔部分, 核技巧等将在下篇中介绍。 2. SVM模型引入 SVM模型就是找到一个超平面将两类数据点分隔开，这个超平面记为f(\boldsym">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aigonna.com/img/imgs/8.jpg">
<meta property="article:published_time" content="2020-07-25T15:11:31.000Z">
<meta property="article:modified_time" content="2021-06-01T12:12:11.927Z">
<meta property="article:author" content="aigonna">
<meta property="article:tag" content="SVM">
<meta property="article:tag" content="硬间隔">
<meta property="article:tag" content="软间隔">
<meta property="article:tag" content="对偶问题">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aigonna.com/img/imgs/8.jpg"><link rel="shortcut icon" href="/img/AI.png"><link rel="canonical" href="http://aigonna.com/2020/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC6%20SVM%20%E4%B8%8A/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-01 20:12:11'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><link rel="stylesheet" href="/css/bg.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/AI.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">77</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">185</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/imgs/8.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">aigonna</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习-白板推导6 SVM 上</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2020-07-25T15:11:31.000Z" title="undefined 2020-07-25 23:11:31">2020-07-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="机器学习-白板推导6-SVM-上"><a href="#机器学习-白板推导6-SVM-上" class="headerlink" title="机器学习-白板推导6 SVM 上"></a>机器学习-白板推导6 SVM 上</h3><h4 id="1-SVM-核心知识点"><a href="#1-SVM-核心知识点" class="headerlink" title="1.SVM 核心知识点"></a>1.SVM 核心知识点</h4><p>Support Vector Machine(SVM) 有三宝，间隔，对偶，核技巧。其分类有：</p>
<ol>
<li><strong>Hard-margin SVM</strong> </li>
<li><strong>Soft-margin SVM</strong> </li>
<li><strong>Kernel SVM</strong></li>
</ol>
<p>本文将介绍软硬间隔部分, 核技巧等将在下篇中介绍。</p>
<h4 id="2-SVM模型引入"><a href="#2-SVM模型引入" class="headerlink" title="2. SVM模型引入"></a>2. SVM模型引入</h4><p><img src="https://gitee.com/miller999999/bpic/raw/master/img/blog/20210528173540.png" alt="image-20210528173538769" style="zoom:20%;" /></p>
<p>SVM模型就是找到一个超平面将两类数据点分隔开，这个超平面记为<script type="math/tex">f(\boldsymbol{w}) = \boldsymbol{w}^Tx + b</script>。如上图所示，这样的超平面很多，如<script type="math/tex">L_1, L_2, L_3</script>，那么哪个最好呢？直觉上，离这些点距离越远越好。间隔就是相对距离最近的点与超平面的距离，首先先将问题数学化定义。</p>
<p>对于数据集<script type="math/tex">D=\{(\boldsymbol{x}_i,y_i)\}^{N}_{i=1}</script>，其中<script type="math/tex">\boldsymbol{x}_i\in\mathbb{R}^{p}, \ y_i\in\{1,-1\}</script>。要将数据点分隔开的间隔最大化，并且要将所有点分类正确：</p>
<script type="math/tex; mode=display">
\max \text{ margin}  (\boldsymbol{w},b) \\
       s.t. \
        \left\{
        \begin{array}{ll}
            \boldsymbol{w}^T_ix+b>0  \quad y_i = +1 \\
            \boldsymbol{w}^T_ix+b<0 \quad  y_i = -1 \\
        \end{array}
         \right. \tag{1}</script><p>因为约束条件可改写为：</p>
<script type="math/tex; mode=display">
s.t. \quad y_i(\boldsymbol{w}_i^Tx + b) > 0, \quad (i=1, 2, \cdots, N) \tag{2}</script><p>对于间隔，即样本空间点到超平面<script type="math/tex">(\boldsymbol{w}, b)</script>的最小距离可写作：</p>
<script type="math/tex; mode=display">
\begin{align}
&\min \frac{1}{\lVert \boldsymbol{w} \rVert} |\boldsymbol{w}^T\boldsymbol{x}_i + b| \quad \quad  (i=1, 2, \cdots, N )
\\= &\min \frac{1}{\lVert \boldsymbol{w} \rVert} y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b)
\\=&\frac{1}{\lVert \boldsymbol{w} \rVert} \min\ y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b)

\end{align}
\tag{3}</script><p>进一步简化问题，式2中约束是<script type="math/tex">y_i(\boldsymbol{w}_i^Tx + b) > 0</script>,那么<script type="math/tex">\exists \gamma \gt 0, \ 令\min\ y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) = \gamma</script>。这时最小间隔就是<script type="math/tex">\gamma</script>， 对于所有点都应该大于等于最小间隔，<script type="math/tex">y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge \gamma</script>。目标函数整理后：</p>
<script type="math/tex; mode=display">
\max_{\boldsymbol{w}, b} \frac{\gamma}{\lVert \boldsymbol{w} \rVert } \quad \quad s.t. \quad y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge \gamma \tag{4}</script><p>但是有个问题<script type="math/tex">\gamma</script>是<strong>函数间隔</strong>，就是<script type="math/tex">\boldsymbol{w}， b</script>放大为2倍时，<strong>函数间隔</strong>也会扩大。因此要约束。不妨令<script type="math/tex">\gamma = 1</script>, 并且这时式4中<script type="math/tex">\max_{\boldsymbol{w}, b} \frac{1}{\lVert \boldsymbol{w} \rVert }</script>等价于<script type="math/tex">\min_{\boldsymbol{w}, b} \frac{1}{2}\lVert \boldsymbol{w} \rVert ^2 = \min_{\boldsymbol{w}, b} \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w}</script> （最大导数变为最小其互导数，并且为了简化计算改写下）。这时目标函数改写为：</p>
<script type="math/tex; mode=display">
\left \{ 
\begin{array}{ll}
\min_{\boldsymbol{w}, b} \ \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w}\\
\text{s.t} \quad y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1, \quad i=1, \cdots, N
\end{array}
\right. 
\tag{5}</script><h4 id="3-SVM-模型求解-硬间隔"><a href="#3-SVM-模型求解-硬间隔" class="headerlink" title="3. SVM 模型求解(硬间隔)"></a>3. SVM 模型求解(硬间隔)</h4><p>上节中式5 是带约束的优化问题，可以用拉格朗日乘子法来求解。</p>
<p>其拉格朗日函数为：</p>
<script type="math/tex; mode=display">
L(\boldsymbol{w}, b, \lambda) = \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} + \sum_{i=1}^{N} \lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b)) \tag{6}</script><p>其中<script type="math/tex">\lambda_i \ge 0</script>. 如果其等于0，就没有约束条件了，变为直接取最小值。</p>
<p><strong>关于<script type="math/tex">\lambda_i \gt 0</script>原因</strong>：因为要目标函数的梯度和可行域的梯度要平行且同向，<script type="math/tex">-\nabla_{\boldsymbol{x}}f(x) = \lambda \nabla_{\boldsymbol{x}}g(x) \quad 且 \lambda \gt 0</script>。如果小于0，就反向了。</p>
<p><img src="https://gitee.com/miller999999/bpic/raw/master/img/blog/20210530105856.png" alt="image-20210530105847439" style="zoom:25%;" /></p>
<p><a target="_blank" rel="noopener" href="https://www.csc.kth.se/utbildning/kth/kurser/DD3364/Lectures/KKT.pdf">具体看这个KKT</a>。</p>
<p>那么式6和式5约束问题为什么等价呢？</p>
<p>令<script type="math/tex">\Delta =1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b)</script>有：</p>
<ul>
<li><p>若<script type="math/tex">\Delta \gt 0</script>,那么 <script type="math/tex">\sum_{i=1}^{N} \lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b))</script>将取到无穷大，所以<script type="math/tex">\max_{\lambda} L(\boldsymbol{w}, b, \lambda) = \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} + \infty =\infty</script></p>
</li>
<li><p>若<script type="math/tex">\Delta \le 0</script>, 当<script type="math/tex">\lambda_i = 0</script>时, 则<script type="math/tex">\sum_{i=1}^{N} \lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b))</script>取最大值0，因此<script type="math/tex">\max_{\lambda} L(\boldsymbol{w}, b, \lambda) = \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} + 0=\frac{1}{2} \boldsymbol{w}^T\boldsymbol{w}</script></p>
<p>综上所述，<script type="math/tex">\min_{\boldsymbol{w}, b} \max_{\lambda} L(\boldsymbol{w}, b, \lambda)  = \min_{\boldsymbol{w}, b} \{\infty, \ \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w}\}</script>将取<script type="math/tex">\frac{1}{2} \boldsymbol{w}^T\boldsymbol{w}</script>。这样隐式地保证了 <script type="math/tex">\Delta =1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \le 0</script> 来满足约束条件。</p>
</li>
</ul>
<p>现在<strong>原问题：</strong></p>
<script type="math/tex; mode=display">
\left \{ 
\begin{array}{ll}
\min_{\boldsymbol{w}, b } \max_{\lambda }  \ L(\boldsymbol{w}, b, \lambda)  \\
\text{s.t} \quad \lambda_i \ge 0
\end{array}
\right. 
\tag{7}</script><p>将其转化为<strong>对偶问题是</strong>：</p>
<script type="math/tex; mode=display">
\left \{ 
\begin{array}{ll}
\max_{\lambda }  \min_{\boldsymbol{w}, b }  \ L(\boldsymbol{w}, b, \lambda)  \\
\text{s.t} \quad \lambda_i \ge 0
\end{array}
\right. 
\tag{8}</script><p>简单介绍下对偶问题，具体看《统计学习方法》 P448。</p>
<p>式7中拉格朗日乘子法的极小极大问题的对偶问题是极大极小问题。</p>
<p>并满足<script type="math/tex">\min  \max L \ge \max \min L</script>，因为对于该不等式，<script type="math/tex">\min  \max L</script>最优解在最大值里面取最小的，而<script type="math/tex">\max \min L</script>是最小值里面取最大的。类似于“宁为鸡头不为凤尾”。</p>
<p>弱对偶关系就是：<script type="math/tex">\min\max \geq \max\min L</script>。</p>
<p>强对偶关系就是：<script type="math/tex">\min\max L  = \max\min L</script>。</p>
<p><strong>求解参数值</strong>：</p>
<p>对于目标函数 (转换为求解其对偶问题):</p>
<script type="math/tex; mode=display">
\max_{\lambda} \min_{\boldsymbol{w}, b} L(\boldsymbol{w}, b, \lambda) = \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} + \sum_{i=1}^{N} \lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b)) \quad \quad i=1, \cdots, N \tag{9}</script><p>简化下方便计算：</p>
<script type="math/tex; mode=display">
\begin{align}
   L(\boldsymbol{w},b,\lambda) = & \frac{1}{2}\boldsymbol{w}^T\boldsymbol{w} + \sum_{i=1}^N\lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) \\
    = & \frac{1}{2}\boldsymbol{w}^T\boldsymbol{w} + \sum_{i=1}^N\lambda_i - \sum_{i=1}^N\lambda_iy_i\boldsymbol{w}^T\boldsymbol{x}_i - \sum_{i=1}^N\lambda_iy_ib \\

\end{align} \tag{10}</script><ol>
<li>对参数<script type="math/tex">b</script>求导：</li>
</ol>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial b} = -\sum_{i=1}^N\lambda_iy_i \tag{11}</script><ol>
<li>对参数<script type="math/tex">\boldsymbol{w}</script>求导，先将式11代入式10，然后求导。</li>
</ol>
<script type="math/tex; mode=display">
L(\boldsymbol{w},b,\lambda) = \frac{1}{2}\boldsymbol{w}^T\boldsymbol{w} + \sum_{i=1}^N\lambda_i - \sum_{i=1}^N\lambda_iy_i\boldsymbol{w}^T\boldsymbol{x}_i \tag{12}</script><p>对其求导得：</p>
<script type="math/tex; mode=display">
\frac{\partial L}{\partial \boldsymbol{w}} = \boldsymbol{w} -\sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i = 0 \tag{13}</script><p>这里<script type="math/tex">\boldsymbol{w}^\star = \sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i</script>是样本数据的线性组合。</p>
<ol>
<li>求解 <script type="math/tex">\min_{\boldsymbol{w}, b} L(\boldsymbol{w}, b, \lambda)</script>, 依旧将<script type="math/tex">\boldsymbol{w}^\star</script>代入式12得：</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
\min_{\boldsymbol{w}, b} L(\boldsymbol{w}, b, \lambda)  &= \frac{1}{2} (\sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i)^T\sum_{j=1}^N\lambda_jy_j\boldsymbol{x}_j +\sum_{i=1}^N\lambda_i - \sum_{i=1}^N\lambda_iy_i(\sum_{j=1}^N\lambda_jy_j\boldsymbol{x}_j)^T\boldsymbol{x}_i
\\ &= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N\lambda_i\lambda_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j +\sum_{i=1}^N\lambda_i 
\end{align}
\tag{14}</script><p>现在问题简化为：</p>
<script type="math/tex; mode=display">
\begin{align}
\max_{\lambda}  L(\boldsymbol{w}, b, \lambda) & = -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N\lambda_i\lambda_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j +\sum_{i=1}^N\lambda_i 
\\ 
&\text{s.t. } \quad \lambda_i \ge 0, \quad\sum_{i=1}^N\lambda_iy_i = 0, \quad i=1, \cdots, N
\end{align}
\tag{15}</script><h4 id="4-SVM-KKT条件导出"><a href="#4-SVM-KKT条件导出" class="headerlink" title="4. SVM KKT条件导出"></a>4. SVM KKT条件导出</h4><p>KKT条件实际上由以下部分构成：</p>
<ol>
<li>目标函数和所有约束条件组成的拉格朗日函数的梯度为0。</li>
<li>互补松弛条件（complementary slackness）， 就是不等式约束和其拉格朗日系数积为0。</li>
<li>不等式约束条件</li>
<li>等式约束条件</li>
<li>拉格朗日系数约束</li>
</ol>
<p>其中，互补松弛条件解释跟小节3中<script type="math/tex">\lambda_i \ge 0</script>部分类似，还可以看看关于这个得解释<a target="_blank" rel="noopener" href="https://www.cnblogs.com/massquantity/p/10807311.html">拉格朗日乘子法 - KKT条件 - 对偶问题</a>。</p>
<p>导出式15的KKT条件为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \left\{
    \begin{array}{ll}
          \frac{\partial L}{\partial \boldsymbol{w}} = 0,\quad
          \frac{\partial L}{\partial b} = 0,\quad
          \frac{\partial L}{\partial \lambda} = 0 & \\
          \lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) = 0 & \\
          1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b) \leq 0 &\\
          \lambda_i \geq 0 & \\

    \end{array}
    \right.
\end{equation} \tag{16}</script><p>其中式16中第二排等式就是互补松弛条件。满足KKT条件是原问题的对偶问题具有强对偶关系的充分条件，当然也包括目标函数<script type="math/tex">f(x)</script>和不等式约束为凸函数，等式约束为仿射函数这些必备条件。</p>
<p>根据小节3中，<script type="math/tex">\boldsymbol{w}^\star = \sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i</script>。</p>
<p>那么<script type="math/tex">b^{\star}</script>呢？这时使用互补松弛条件来求解，<script type="math/tex">\lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) = 0</script>。</p>
<p>再解释下具体SVM中这个条件是怎么来的。如下图，图来自于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Support-vector_machine">Wiki SVM</a></p>
<p><img src="https://gitee.com/miller999999/bpic/raw/master/img/blog/20210528170847.png" alt="image-20210528170838009" style="zoom:20%;" /></p>
<p>图中距离分割超平面最近的点都落在<script type="math/tex">y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b) = \pm 1</script>上，这些点叫<strong>支持向量</strong>。SVM算法最核心部分就是找支持向量。</p>
<p>对于支持向量，必然有<script type="math/tex">1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)=0</script>，那么<script type="math/tex">\lambda_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) = 0</script>中<script type="math/tex">\lambda_i</script>才有可能取值(<script type="math/tex">\lambda_i \neq 0</script>)。其它点的话，<script type="math/tex">\lambda_i = 0</script>。</p>
<p>不妨假设一个支持向量为<script type="math/tex">(\boldsymbol{x}_k, y_k)</script>那么，</p>
<script type="math/tex; mode=display">
\begin{align}
&1-y_k(\boldsymbol{w}^T\boldsymbol{x}_k+b)=0 \\
&\Longrightarrow y_kb^{\star} = 1-y_k\boldsymbol{w^{\ast ^T}}\boldsymbol{x}_k\\
&\Longrightarrow  b^{\star} = y_k-\boldsymbol{w^{\ast ^T}}\boldsymbol{x}_k \quad \quad 因为y_k= \pm 1 \\
& \Longrightarrow  b^{\star} =  y_k -\sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i\boldsymbol{x}_k 
\end{align} \tag{17}</script><p><strong>总结</strong>：</p>
<p>到此为止，我们求出了硬间隔的SVM的最优解，模型为：</p>
<script type="math/tex; mode=display">
f(\boldsymbol{x}) = \text{sign }(\boldsymbol{w^{\ast ^T}}\boldsymbol{x} + b^{\star} ) \tag{18}</script><p>其中，<script type="math/tex">\boldsymbol{w}^\star = \sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i, \quad b^{\star} = y_k -\sum_{i=1}^N\lambda_iy_i\boldsymbol{x}_i\boldsymbol{x}_k</script></p>
<p>并且KKT条件是原问题的对偶问题有强对偶关系的充要条件，利用支持向量求解SVM计算相对简单。支持向量寻找过程是通过代入数据点，从满足式15中当<script type="math/tex">\lambda_i=0</script>时，对应数据点就是是支持向量。具体计算算法看SVM SMO这节。</p>
<h4 id="5-SVM-软间隔"><a href="#5-SVM-软间隔" class="headerlink" title="5. SVM 软间隔"></a>5. SVM 软间隔</h4><p>上面介绍的SVM要求数据集能完全被分开，不能有数据点噪声落在硬间隔区间内，但是数据集必然有噪声等落在这个区间。Soft Margin就是允许一些点落在margin内。</p>
<p><img src="https://gitee.com/miller999999/bpic/raw/master/img/blog/20210531155655.png" alt="image-20210531155653799" style="zoom:25%;" /></p>
<p>如上图中，对于要分类的两类数据点，落入蓝色实线之间的点就是被误分类的，图中A点，那么<script type="math/tex">y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b) \lt 1</script>。如果有多个呢？我们引入指示函数有：</p>
<script type="math/tex; mode=display">
\text{loss} =\sum_{i=1}^{N} I \{y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)) \lt 1\}</script><p>其中<script type="math/tex">I</script>是指示函数，不连续，不可导。</p>
<p>不妨将其转换为距离来看损失函数。</p>
<ul>
<li>若<script type="math/tex">y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b) \ge 1</script>,正确分类，损失为0</li>
<li>若<script type="math/tex">y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b) \lt 1</script>，距离为图中<script type="math/tex">\epsilon</script>,  <script type="math/tex">1 - y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)</script></li>
</ul>
<p>用max来合并下这些距离，<script type="math/tex">\text{loss} =   \max\{0, 1 - y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\}</script>，这个函数叫hinge loss。</p>
<p>现在式5，加上合页损失就是目标函数：</p>
<script type="math/tex; mode=display">
\left \{ 
\begin{array}{ll}
\min_{\boldsymbol{w}, b} \ \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} + C\sum_{i=1}^N \max\{0, 1 - y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\}\\
\text{s.t} \quad y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1, \quad i=1, \cdots, N
\end{array}
\right. 
\tag{19}</script><p>其中，C是惩罚系数，有点像正则化中的系数。</p>
<p>令<script type="math/tex">\xi_i =  1 - y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)</script>, 因为其是距离<script type="math/tex">\xi_i \ge 0</script>。式19就可以简化为：</p>
<script type="math/tex; mode=display">
\left \{ 
\begin{array}{ll}
\min_{\boldsymbol{w}, b} \ \frac{1}{2} \boldsymbol{w}^T\boldsymbol{w} +  C\sum_{i=1}^N \xi_i \\
\text{s.t} \quad y_i(\boldsymbol{w}^T\boldsymbol{x}_i + b) \ge 1-\xi_i, \quad \xi_i \ge 0, \ i=1, \cdots, N
\end{array}
\right. 
\tag{20}</script><p>如上图中，<script type="math/tex">1- \xi_i</script>就是允许误分类点到分类边界的距离，也可以认为是允许误分类点的范围。接下来也可以用拉格朗日乘子法求解。</p>
<h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><p>[1] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49331510">看了这篇文章你还不懂SVM你就来打我</a></p>
<p>[2] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/335017540">支持向量机SVM（Support Vector Machine）笔记</a></p>
<p>[3] <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/eeb33ce6bc6d">支持向量机</a></p>
<p>[4] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38182879">拉格朗日对偶性</a> </p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">aigonna</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://aigonna.com/2020/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC6%20SVM%20%E4%B8%8A/">http://aigonna.com/2020/07/25/机器学习-白板推导6 SVM 上/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://aigonna.com" target="_blank">aigonna</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/SVM/">SVM</a><a class="post-meta__tags" href="/tags/%E7%A1%AC%E9%97%B4%E9%9A%94/">硬间隔</a><a class="post-meta__tags" href="/tags/%E8%BD%AF%E9%97%B4%E9%9A%94/">软间隔</a><a class="post-meta__tags" href="/tags/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98/">对偶问题</a></div><div class="post_share"><div class="social-share" data-image="/img/imgs/8.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/07/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC7%20%E6%A0%B8%E6%96%B9%E6%B3%95/"><img class="prev-cover" src="/img/imgs/11.jpg" onerror="onerror=null;src='/img/imgs/0.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">机器学习-白板推导 7 核方法</div></div></a></div><div class="next-post pull-right"><a href="/2020/07/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC5%20%E9%99%8D%E7%BB%B4/"><img class="next-cover" src="/img/imgs/2.jpg" onerror="onerror=null;src='/img/imgs/0.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">机器学习-白板推导 5 降维</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%99%BD%E6%9D%BF%E6%8E%A8%E5%AF%BC6-SVM-%E4%B8%8A"><span class="toc-text">机器学习-白板推导6 SVM 上</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-SVM-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-text">1.SVM 核心知识点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-SVM%E6%A8%A1%E5%9E%8B%E5%BC%95%E5%85%A5"><span class="toc-text">2. SVM模型引入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-SVM-%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3-%E7%A1%AC%E9%97%B4%E9%9A%94"><span class="toc-text">3. SVM 模型求解(硬间隔)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-SVM-KKT%E6%9D%A1%E4%BB%B6%E5%AF%BC%E5%87%BA"><span class="toc-text">4. SVM KKT条件导出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-SVM-%E8%BD%AF%E9%97%B4%E9%9A%94"><span class="toc-text">5. SVM 软间隔</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inference"><span class="toc-text">Inference</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021&nbsp;<i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;"class="fas fa-heart"></i> By aigonna</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      //tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'forest',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: '5sVUTO1MTpgoo7pDynh6zYEM-MdYXbMMI',
      appKey: 'vPUvOT1iP6YqcPPtYSqf8F7A',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script><h4>AIgonna</h4></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script></div></body></html>
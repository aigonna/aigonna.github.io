<!DOCTYPE html><html class="hide-aside" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Chapter 06 Probability and Distributions | aigonna</title><meta name="keywords" content="机器学习,Mathematic for machine learning 笔记,高斯分布,Probability"><meta name="author" content="miller"><meta name="copyright" content="miller"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Chapter 06: Probability and Distributions 中英名词对照： PMF：Probability Mass Function(概率质量函数) PDF： Probability Density Function(概率密度函数) CDF：Cumulative Distribution Function (累积分布函数) i.i.d：Independent and id">
<meta property="og:type" content="article">
<meta property="og:title" content="Chapter 06 Probability and Distributions">
<meta property="og:url" content="http://aigonna.com/2020/04/04/M4ML_Chapter06-Probability-and-Distributions/index.html">
<meta property="og:site_name" content="aigonna">
<meta property="og:description" content="Chapter 06: Probability and Distributions 中英名词对照： PMF：Probability Mass Function(概率质量函数) PDF： Probability Density Function(概率密度函数) CDF：Cumulative Distribution Function (累积分布函数) i.i.d：Independent and id">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aigonna.com/img/ach.jpg">
<meta property="article:published_time" content="2020-04-04T05:49:39.000Z">
<meta property="article:modified_time" content="2021-06-08T03:42:40.627Z">
<meta property="article:author" content="miller">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Mathematic for machine learning 笔记">
<meta property="article:tag" content="高斯分布">
<meta property="article:tag" content="Probability">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aigonna.com/img/ach.jpg"><link rel="shortcut icon" href="/img/AI.png"><link rel="canonical" href="http://aigonna.com/2020/04/04/M4ML_Chapter06-Probability-and-Distributions/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}

// https://stackoverflow.com/questions/16839698/jquery-getscript-alternative-in-native-javascript
const getScript = url => new Promise((resolve, reject) => {
  const script = document.createElement('script')
  script.src = url
  script.async = true
  script.onerror = reject
  script.onload = script.onreadystatechange = function() {
    const loadState = this.readyState
    if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
    script.onload = script.onreadystatechange = null
    resolve()
  }
  document.head.appendChild(script)
})</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-06-08 11:42:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }const asideStatus = saveToLocal.get('aside-status')
if (asideStatus !== undefined) {
   if (asideStatus === 'hide') {
     document.documentElement.classList.add('hide-aside')
   } else {
     document.documentElement.classList.remove('hide-aside')
   }
}})()</script><link rel="stylesheet" href="/css/bg.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/AI.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">73</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">167</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/ach.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">aigonna</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Chapter 06 Probability and Distributions</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2020-04-04T05:49:39.000Z" title="undefined 2020-04-04 13:49:39">2020-04-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>28分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Chapter-06-Probability-and-Distributions"><a href="#Chapter-06-Probability-and-Distributions" class="headerlink" title="Chapter 06: Probability and Distributions"></a>Chapter 06: Probability and Distributions</h2><ul>
<li><p>中英名词对照：</p>
<p>PMF：Probability Mass Function(概率质量函数)</p>
<p>PDF： Probability Density Function(概率密度函数)</p>
<p>CDF：Cumulative Distribution Function (累积分布函数)</p>
<p>i.i.d：Independent and identically distributed</p>
<p>median: 中位数</p>
<p>mode： 众数</p>
</li>
</ul>
<h3 id="1-Sum-Rule-Product-Rule-and-Bayes’-Theorem"><a href="#1-Sum-Rule-Product-Rule-and-Bayes’-Theorem" class="headerlink" title="1. Sum Rule, Product Rule, and Bayes’ Theorem"></a>1. Sum Rule, Product Rule, and Bayes’ Theorem</h3><ul>
<li><p><strong>sum rule</strong>:</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x})=
\left\{\begin{array}{ll}
\sum_{\boldsymbol{y} \in \mathcal{Y}} p(\boldsymbol{x}, \boldsymbol{y}) & \text { if } \boldsymbol{y} \text { is discrete } \\
\int_{\mathcal{Y}} p(\boldsymbol{x}, \boldsymbol{y}) \mathrm{d} \boldsymbol{y} & \text { if } \boldsymbol{y} \text { is continuous }
\end{array}\right. \tag{1}</script></li>
<li><p><strong>product rule</strong></p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}, \boldsymbol{y}) = P \left( \boldsymbol{y} \left|\boldsymbol{x}\right. \right) p(\boldsymbol{x}) \tag{2}</script></li>
</ul>
<ul>
<li><strong>Bayes’ theorem:</strong></li>
</ul>
<script type="math/tex; mode=display">
\underbrace{p(\boldsymbol{x} \mid \boldsymbol{y})}_{\text {posterior }}=\frac{\overbrace{p(\boldsymbol{y} \mid \boldsymbol{x})}^{\text {likelihood }} \overbrace{p(\boldsymbol{x})}^{\text {prior }}}{\underbrace{p(\boldsymbol{y})}_{\text {evidence }}} \tag{3}</script><p><strong>后验概率正比于似然 $\times$ 先验概率</strong></p>
<p><strong>likelihood 也可称作measurement model</strong></p>
<p>  假设我们有一些关于隐变量$\boldsymbol{x}$先验$p(\boldsymbol{x})$，以及关于$\boldsymbol{x}$和第二个变量$\boldsymbol{y}$之间的关系$p \left( \boldsymbol{y} \left|\boldsymbol{x}\right. \right)$。如果我们观察$\boldsymbol{y}$,我们可以使用Bayes’理论来得到公式3.</p>
<p>  $p(\boldsymbol{x})$，封装了我们在观察任何数据之前对隐变量$\boldsymbol{x}$主观先验知识。我们可以选择任何对我有意义的先验知识，但至关重要的是确保先验在所有可能的$\boldsymbol{x}$有非零的pdf,即使其非常罕见。</p>
<p>  似然${p(\boldsymbol{y} \mid \boldsymbol{x})}$描述$\boldsymbol{x}$和$\boldsymbol{y}$直接的关系，并且在离散概率分布情况下，如果我们知道隐变量$\boldsymbol{x}$,它是数据$\boldsymbol{y}$的概率。注意，似然不是$\boldsymbol{x}$的分布，而是$\boldsymbol{y}$。<strong>我们称${p(\boldsymbol{y} \mid \boldsymbol{x})}$为给定$\boldsymbol{y}$的$\boldsymbol{x}$的似然，或给定$\boldsymbol{x}$的$\boldsymbol{y}$的概率， 但绝对不能称$\boldsymbol{y}$的似然</strong>。</p>
<p>后验${p(\boldsymbol{x} \mid \boldsymbol{y})}$得益于大量Bayes统计学，因为它准确表达了我们在观察$\boldsymbol{y}$后了解$\boldsymbol{x}$的兴趣。</p>
<blockquote>
<p>根据贝叶斯定理公式3，一个随机变量在给定另一随机变量值之后的后验概率分布可以通过先验概率分布与似然函数相乘并除以归一化常数求得<br>: </p>
<script type="math/tex; mode=display">
f_{X\mid Y=y}(x)={f_X(x) L_{X\mid Y=y}(x) \over {\int_{-\infty}^\infty f_X(u) L_{X\mid Y=y}(u)\,du}} \tag{4}</script><p>上式为给出了随机变量$X$在给定数据$Y=y$后的后验概率分布函数，式中</p>
<ul>
<li><script type="math/tex">f_X(x)></script>  为  <script type="math/tex">X</script>  的先验密度函数，</li>
<li><script type="math/tex">L_{X\mid Y=y}(x) = f_{Y\mid X=x}(y)</script>   为   <script type="math/tex">x</script>   的似然函数，</li>
<li><script type="math/tex">\int_{-\infty}^\infty f_X(u) L_{X\mid Y=y}(u)du</script>   为归一化常数，</li>
<li><script type="math/tex">f_{X\mid Y=y}(x)</script> 为考虑了数据 <script type="math/tex">Y=y</script> 后 <script type="math/tex">X</script> 的后验密度函数。</li>
</ul>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Posterior_probability">注:引用自维基/后验概率</a></p>
<h4 id="1-Likelihood-function"><a href="#1-Likelihood-function" class="headerlink" title="1. Likelihood function"></a>1. Likelihood function</h4><blockquote>
<p>In statistics, the likelihood function often simply called the likelihood <strong>measures the goodness of fit of a statistical model to a sample of data for given values of the unknown parameters</strong>. It is formed from the joint probability distribution of the sample, but viewed and used as a function of the parameters only, thus treating the random variables as fixed at the observed values.</p>
<p>在数理统计学中，<strong>似然函数</strong>是一种关于统计模型中的<strong>参数</strong>的<strong>函数</strong>，表示模型参数中的<strong>似然性</strong>。似然函数在统计推断中有重大作用，如在最大似然估计和费雪信息之中的应用等等。“似然性”与“或然性”或“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然性”和“概率”（或然性）又有明确的区分：<u>概率，用于在已知一些参数的情況下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值</u>。</p>
<p>在这种意义上，似然函数可以理解为条件概率的逆反。在已知某个参数$B$时，事件$A$会发生的概率写作：</p>
<script type="math/tex; mode=display">
P(A \mid B) = \frac{P(A , B)}{P(B)}</script><p>利用贝叶斯定理，</p>
<script type="math/tex; mode=display">
P(B \mid A) = \frac{P(A \mid B)\;P(B)}{P(A)}</script><p>因此，我们可以反过来构造表示似然性的方法：已知有事件$A$发生，运用似然函数$\mathbb{L}(B \mid A)$，我们估计参数$B$的可能性。形式上，似然函数也是一种条件概率函数，但我们关注的变量改变了：</p>
<script type="math/tex; mode=display">
b\mapsto P(A \mid B=b)</script><p>注意到这里并不要求似然函数满足归一性：$\sum_{b \in \mathcal{B}}P(A \mid B=b) = 1$。一个似然函数乘以一个正的常数之后仍然是似然函数。对所有$\alpha &gt; 0$，都可以有似然函数:</p>
<script type="math/tex; mode=display">
L(b \mid A) = \alpha \; P(A \mid B=b)</script></blockquote>
<p><a href="[https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0](https://zh.wikipedia.org/wiki/似然函数">注:引用自维基/似然函数</a>)</p>
<h4 id="2-边缘似然-证据"><a href="#2-边缘似然-证据" class="headerlink" title="2.  边缘似然/证据"></a>2.  边缘似然/证据</h4><ul>
<li>the marginal likehood/evidence：</li>
</ul>
<script type="math/tex; mode=display">
p(\boldsymbol{y}):=\int p(\boldsymbol{y} \mid \boldsymbol{x}) p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}=\mathbb{E}_{X}[p(\boldsymbol{y} \mid \boldsymbol{x})] \tag{5}</script><p>定义上，边缘似然是对应隐变量$x$数值积分。</p>
<blockquote>
<p>在统计学中， 边缘似然函数（marginal likelihood function），或积分似然（integrated likelihood），是一个某些参数变量边缘化的似然函数（likelihood function） 。在贝叶斯统计范畴，它也可以被称作为 证据 或者 模型证据 的。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/边缘似然">引用:维基/边缘似然</a></p>
<h3 id="2-均值和协方差"><a href="#2-均值和协方差" class="headerlink" title="2. 均值和协方差"></a>2. 均值和协方差</h3><ul>
<li>Means and Covariances</li>
</ul>
<p>均值和(协)方差经常用来描述概率分布的性质(期望值和范围)。</p>
<p>期望值的概念是机器学习的核心，并且概率本身的基础概念也源自于它。</p>
<p>​                                                                                                                        ——(Whittle, 2000).</p>
<h4 id="1-期望值"><a href="#1-期望值" class="headerlink" title="1. 期望值"></a>1. 期望值</h4><ul>
<li>Expected Value</li>
</ul>
<p>期望值函数$g: \mathbb{R} \rightarrow \mathbb{R}$单一连续随机变量$X \sim p(x)$给定如下：</p>
<script type="math/tex; mode=display">
\mathbb{E}_{X}[g(x)]=\int_{\mathcal{X}} g(x) p(x) \mathrm{d} x \tag{6}</script><p>对应离散随机变量$X \sim p(x)$:</p>
<script type="math/tex; mode=display">
\mathbb{E}_{X}[g(x)]=\sum_{x \in \mathcal{X}} g(x) p(x) \tag{7}</script><p>$\mathcal{X}$：随机变量$X$可能结果的集合 target space</p>
<p><strong>注意：</strong></p>
<p>我们把多维随机变量$X$看作有限的单一随机变量的向量$[X_1, \cdots, X_D]^{T}$。对于多维随机变量,定义基于元素的期望值：</p>
<script type="math/tex; mode=display">
\mathbb{E}_{X}[g(\boldsymbol{x})]=\left[\begin{array}{c}
\mathbb{E}_{X_{1}}\left[g\left(x_{1}\right)\right] \\
\vdots \\
\mathbb{E}_{X_{D}}\left[g\left(x_{D}\right)\right]
\end{array}\right] \in \mathbb{R}^{D} \tag{8}</script><p>其中：  <script type="math/tex">{\mathbb{E}_{X}}_{d}</script>   表示对应向量  <script type="math/tex">x</script>  的第   <script type="math/tex">d</script>  个元素的期望值。</p>
<h4 id="2-均值"><a href="#2-均值" class="headerlink" title="2. 均值"></a>2. 均值</h4><p>对于状态量<script type="math/tex">x \in \mathbb{R}^{D}</script> 随机变量 <script type="math/tex">X</script> 的均值是一个平均值，其定义如下：</p>
<script type="math/tex; mode=display">
\begin{align}
&\mathbb{E}_{X}[\boldsymbol{x}]=\left[\begin{array}{c}
\mathbb{E}_{X_{1}}\left[x_{1}\right] \\
\vdots \\
\mathbb{E}_{X_{D}}\left[x_{D}\right]
\end{array}\right] \in \mathbb{R}^{D}, 

\\ &\text{where}
\\
\\ &\mathbb{E}_{x_{d}}\left[x_{d}\right]:=\left\{\begin{array}{ll}\int_{\mathcal{X}} x_{d} p\left(x_{d}\right) \mathrm{d} x_{d} & \text { if } X \text { is a continuous random variable } \\ \sum_{x_{i} \in \mathcal{X}} x_{i} p\left(x_{d}=x_{i}\right) & \text { if } X \text { is a discrete random variable }\end{array}\right. \tag{9}

\end{align}</script><p>其中，$d = 1, \cdots, D$;$d$表示对应$x$的维数。遍历随机变量$x$目标空间的状态量$\mathcal{X}$积分或求和。</p>
<h4 id="3-协方差-Covariance-定义及推导"><a href="#3-协方差-Covariance-定义及推导" class="headerlink" title="3. 协方差(Covariance)定义及推导"></a>3. 协方差(Covariance)定义及推导</h4><p>两个多维随机变量$X, Y \in \mathbb{R}$之间的协方差，给定为它们与均值的偏差的积的期望：</p>
<script type="math/tex; mode=display">
\operatorname{Cov}_{X, Y}[x, y]:=\mathbb{E}_{X, Y}\left[\left(x-\mathbb{E}_{X}[x]\right)\left(y-\mathbb{E}_{Y}[y]\right)\right] \tag{10}
\</script><p>因为期望计算是线性的，对于一个实值函数$f(\boldsymbol{x}) = ag(\boldsymbol{x}) + bh(\boldsymbol{x})$， 当$a, b \in \mathbb{R} 且 \boldsymbol{x} \in \mathbb{R}^{D}$我们可以得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}_{X}[f(\boldsymbol{x})] &=\int f(\boldsymbol{x}) p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x} \\
&=\int[a g(\boldsymbol{x})+b h(\boldsymbol{x})] p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x} \\
&=a \int g(\boldsymbol{x}) p(\boldsymbol{x}) \mathrm{d} x+b \int h(\boldsymbol{x}) p(\boldsymbol{x}) \mathrm{d} \boldsymbol{x} \\
&=a \mathbb{E}_{X}[g(\boldsymbol{x})]+b \mathbb{E}_{X}[h(\boldsymbol{x})]
\end{aligned} \tag{11}</script><p>所以，公式10可以有如下推导：</p>
<script type="math/tex; mode=display">
\begin{align}
\operatorname{Cov}_{X, Y}[x, y]&=\mathbb{E}_{X, Y}\left[\left(x-\mathbb{E}_{X}[x]\right)\left(y-\mathbb{E}_{Y}[y]\right)\right]

\\ &=\mathbb{E}_{X, Y}\left[\left(xy - y\mathbb{E}_{X}[x] - x\mathbb{E}_{Y}[y] +  \mathbb{E}_{X}[x] \mathbb{E}_{Y}[y]\right)\right]

\\ &= \mathbb{E}(xy) -\mathbb{E}[x]\mathbb{E}[y] -\mathbb{E}[x]\mathbb{E}[y] + \mathbb{E}[x]\mathbb{E}[y]

\\ &= \mathbb{E}(xy) -\mathbb{E}[x]\mathbb{E}[y] 
\end{align}</script><p>即：</p>
<script type="math/tex; mode=display">
\begin{align}
\operatorname{Cov}_{X, Y}[x, y] = \mathbb{E}(xy) -\mathbb{E}[x]\mathbb{E}[y]  \tag{12}
\end{align}</script><h4 id="4-多元随机变量的方差"><a href="#4-多元随机变量的方差" class="headerlink" title="4. 多元随机变量的方差"></a>4. 多元随机变量的方差</h4><ul>
<li>Covariance  (Multivariate)</li>
</ul>
<p>两元随机变量$X$和$Y$及其对应状态$\boldsymbol{x} \in \mathbb{R}^{D} 和 \boldsymbol{y} \in \mathbb{R}^{D}$，$X和 Y$之间的协方差为：</p>
<script type="math/tex; mode=display">
\operatorname{Cov}[\boldsymbol{x}, \boldsymbol{y}] = \mathbb{E}[\boldsymbol{x}\boldsymbol{y}^{T}] - \mathbb{E}[\boldsymbol{x}]\mathbb{E}[\boldsymbol{y}]^{T} = \operatorname{Cov}[\boldsymbol{y}, \boldsymbol{x}]^{T} \in \mathbb{R}^{D \times E} \tag{13}</script><h4 id="5-方差"><a href="#5-方差" class="headerlink" title="5. 方差"></a>5. 方差</h4><ul>
<li>Variance</li>
</ul>
<p>带有状态$\boldsymbol{x} \in \mathbb{R}^{D}$和均值向量$\boldsymbol{\mu} \in \mathbb{R}^{D}$的随机变量$X$方差定义为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{V}_{X}[\boldsymbol{x}] &=\operatorname{Cov}_{X}[\boldsymbol{x}, \boldsymbol{x}] \\
&=\mathbb{E}_{X}\left[(\boldsymbol{x}-\boldsymbol{\mu})(\boldsymbol{x}-\boldsymbol{\mu})^{\top}\right]=\mathbb{E}_{X}\left[\boldsymbol{x} \boldsymbol{x}^{\top}\right]-\mathbb{E}_{X}[\boldsymbol{x}] \mathbb{E}_{X}[\boldsymbol{x}]^{\top} \\
&=\left[\begin{array}{cccc}
\operatorname{Cov}\left[x_{1}, x_{1}\right] & \operatorname{Cov}\left[x_{1}, x_{2}\right] & \ldots & \operatorname{Cov}\left[x_{1}, x_{D}\right] \\
\operatorname{Cov}\left[x_{2}, x_{1}\right] & \operatorname{Cov}\left[x_{2}, x_{2}\right] & \ldots & \operatorname{Cov}\left[x_{2}, x_{D}\right] \\
\vdots & \vdots & \ddots & \vdots \\
\operatorname{Cov}\left[x_{D}, x_{1}\right] & \ldots & \ldots & \operatorname{Cov}\left[x_{D}, x_{D}\right]
\end{array}\right]
\end{aligned} \tag{14}</script><p>$D \times D$的矩阵被称作多元随机变量的协方差矩阵 covariance matrix 。协方差矩阵是对称和半正定的，并且告诉我们数据范围的信息。在对角线上，协方差矩阵含有边缘方差：</p>
<script type="math/tex; mode=display">
p\left(x_{i}\right)=\int p\left(x_{1}, \ldots, x_{D}\right) \mathrm{d} x \backslash_{i}p\left(x_{i}\right)=\int p\left(x_{1}, \ldots, x_{D}\right) \mathrm{d} x \backslash_{i} \tag{15}</script><p>$\backslash_{i} $表示”除了$i$之外的所有变量”。非对角线元素是互协方差项$\operatorname {Cov}[x_i, y_i]$,$i, j = 1, \cdots, D, i \ne j$。</p>
<h4 id="6-相关"><a href="#6-相关" class="headerlink" title="6. 相关"></a>6. 相关</h4><ul>
<li>Correlation</li>
</ul>
<p>两个随机变量$X,Y$之间的相关性定义为：</p>
<script type="math/tex; mode=display">
\operatorname{corr}[x, y]=\frac{\operatorname{Cov}[x, y]}{\sqrt{\mathbb{V}[x] \mathbb{V}[y]}} \in[-1,1] \tag{16}</script><center>    <img style="border-radius: 0.3125em;    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"     src="https://i.loli.net/2020/07/02/RTL5JkI9d1GzbQs.png?=raw" width=90% height=90%>    
 <br>    <div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">正负相关示意图 引用自https://mml-book.com</div> </center>

<p>上图中表明，正相关$corr[x, y]$意味着当$x$变大，$y$也随之变大。负相关$corr[x, y]$意味着当$x$变大，$y$也随之变小。</p>
<h3 id="3-经验均值和协方差"><a href="#3-经验均值和协方差" class="headerlink" title="3. 经验均值和协方差"></a>3. 经验均值和协方差</h3><ul>
<li>Empirical Means and Covariances</li>
</ul>
<p>在机器学习中，我们需要从数据中学习经验的观察结果。</p>
<p>我们用有限的数据集 size N 来构建经验统计，它是一个同一随机变量有限数值的函数。</p>
<p>我们观察数据，就是我们看每一个随机变量$x_1, x_2, \cdots, x_N$之间的联系和应用经验统计。</p>
<p>具体来说,对于均值，给定一个特殊的数据集我们获得均值的估计，这称作经验均值或者样本均值sample mean .经验协方差也一样适用。</p>
<h4 id="1-经验均值和协方差"><a href="#1-经验均值和协方差" class="headerlink" title="1. 经验均值和协方差"></a>1. 经验均值和协方差</h4><p>经验均值向量是每一个观察变量的算术平均,其定义如下:</p>
<script type="math/tex; mode=display">
\begin{align}
\overline{\boldsymbol{x}}:=\frac{1}{N} \sum_{n=1}^{N} \boldsymbol{x}_{n} \tag{17} \\ \\ \text{where } {\boldsymbol{x}_{n} \in \mathbb{R}^{D}}

\end{align}</script><p>跟经验均值一样,经验协方差矩阵$D \times D$定义为：</p>
<script type="math/tex; mode=display">
\Sigma:=\frac{1}{N} \sum_{n=1}^{N}\left(x_{n}-\bar{x}\right){\left(x_{n}-\bar{x}\right)}\top \tag{18}</script><p>为了计算特定数据集的统计信息，我们用观察量 <script type="math/tex">\boldsymbol{x}_1, \cdots, \boldsymbol{x}_{N}</script> ，biased estimate 代入公式17.18来计算。经验协方差矩阵是对称半正定的。</p>
<h4 id="2-方差的3种表达式"><a href="#2-方差的3种表达式" class="headerlink" title="2. 方差的3种表达式"></a>2. 方差的3种表达式</h4><h5 id="1-标准方差定义"><a href="#1-标准方差定义" class="headerlink" title="1. 标准方差定义"></a>1. 标准方差定义</h5><p>对应协方差定义，它是随机变量$X$与其期望值$\mu$偏差平方的期望：</p>
<script type="math/tex; mode=display">
\mathbb{V}_{X}[x]:=\mathbb{E}_{X}\left[(x-\mu)^{2}\right] \tag{19}</script><h5 id="2-方差的原始分数公式"><a href="#2-方差的原始分数公式" class="headerlink" title="2. 方差的原始分数公式"></a>2. 方差的原始分数公式</h5><script type="math/tex; mode=display">
\mathbb{V}_{X}[x]=\mathbb{E}_{X}\left[x^{2}\right]-\left(\mathbb{E}_{X}[x]\right)^{2} \tag{20}</script><p>记作：“平方的均值减去均值的平方”。</p>
<h5 id="3-The-sum-of-N-2-pairwise-differences-is-the-empirical-variance-of-the-observations"><a href="#3-The-sum-of-N-2-pairwise-differences-is-the-empirical-variance-of-the-observations" class="headerlink" title="3. The sum of $N^{2}$ pairwise differences is the empirical variance of the observations"></a>3. The sum of $N^{2}$ pairwise differences is the empirical variance of the observations</h5><script type="math/tex; mode=display">
\frac{1}{N^{2}} \sum_{i, j=1}^{N}\left(x_{i}-x_{j}\right)^{2}=2\left[\frac{1}{N} \sum_{i=1}^{N} x_{i}^{2}-\left(\frac{1}{N} \sum_{i=1}^{N} x_{i}\right)^{2}\right] \tag{21}</script><p>当它用到随机变量的仿射变换时，均值和(协)方差表现一些有用的特性。考虑均值为$\boldsymbol{\mu}$、协方差矩阵$\boldsymbol{\Sigma}$随机变量$X$和关于一个$\boldsymbol{x}$(决定论的)仿射变换$\boldsymbol{y} = \boldsymbol{A}\boldsymbol{x} + \boldsymbol{b}$。随机变量$\boldsymbol{y}$，其均值向量和协方差矩阵定义为:</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\mathbb{E}_{Y}[\boldsymbol{y}]=\mathbb{E}_{X}[\boldsymbol{A} \boldsymbol{x}+\boldsymbol{b}]=\boldsymbol{A} \mathbb{E}_{X}[\boldsymbol{x}]+\boldsymbol{b}=\boldsymbol{A} \boldsymbol{\mu}+\boldsymbol{b}  \\  
\mathbb{V}_{Y}[\boldsymbol{y}]=\mathbb{V}_{X}[\boldsymbol{A} \boldsymbol{x}+\boldsymbol{b}]=\mathbb{V}_{X}[\boldsymbol{A} \boldsymbol{x}]=\boldsymbol{A} \mathbb{V}_{X}[\boldsymbol{x}] \boldsymbol{A}^{\top}=\boldsymbol{A} \boldsymbol{\Sigma} \boldsymbol{A}^{\top}  \tag{22}
\end{array}</script><p>而且:</p>
<script type="math/tex; mode=display">
\begin{align}
\operatorname{Cov}[\boldsymbol{x}, \boldsymbol{y}] &=\mathbb{E}\left[\boldsymbol{x}(\boldsymbol{A} \boldsymbol{x}+\boldsymbol{b})^{\top}\right]-\mathbb{E}[\boldsymbol{x}] \mathbb{E}[\boldsymbol{A} \boldsymbol{x}+\boldsymbol{b}]^{\top} \\
&=\mathbb{E}[\boldsymbol{x}] \boldsymbol{b}^{\top}+\mathbb{E}\left[\boldsymbol{x} \boldsymbol{x}^{\top}\right] \boldsymbol{A}^{\top}-\boldsymbol{\mu} \boldsymbol{b}^{\top}-\boldsymbol{\mu} \boldsymbol{\mu}^{\top} \boldsymbol{A}^{\top} \\
&=\boldsymbol{\mu} \boldsymbol{b}^{\top}-\boldsymbol{\mu} \boldsymbol{b}^{\top}+\left(\mathbb{E}\left[\boldsymbol{x} \boldsymbol{x}^{\top}\right]-\boldsymbol{\mu} \boldsymbol{\mu}^{\top}\right) \boldsymbol{A}^{\top} \\
& = \boldsymbol{\Sigma} \boldsymbol{A}^{\top} \tag{23}
\end{align}</script><p>这里，$\boldsymbol{\Sigma} = \mathbb{E}[\boldsymbol{x}\boldsymbol{x}\top] - \boldsymbol{\mu}\boldsymbol{\mu}\top$是$\boldsymbol{X}$的协方差。</p>
<h4 id="3-Statistical-Independence-独立"><a href="#3-Statistical-Independence-独立" class="headerlink" title="3. Statistical Independence(独立)"></a>3. Statistical Independence(独立)</h4><h5 id="1-独立"><a href="#1-独立" class="headerlink" title="1. 独立"></a>1. 独立</h5><p>两个随机变量$X, Y$在统计上独立当且仅当:</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}, \boldsymbol{y}) = p(\boldsymbol{x})p(\boldsymbol{y}) \tag{24}</script><p>直觉地,如果$\boldsymbol{y}$的值不增加$\boldsymbol{x}$任何信息，两个随机变量$X, Y$独立。</p>
<p>如果$X, Y$统计上独立,有：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
p(\boldsymbol{y} \mid \boldsymbol{x})=p(\boldsymbol{y}) \\
p(\boldsymbol{x} \mid \boldsymbol{y})=p(\boldsymbol{x}) \\
\mathbb{V}_{X, Y}[\boldsymbol{x}+\boldsymbol{y}]=\mathbb{V}_{X}[\boldsymbol{x}]+\mathbb{V}_{Y}[\boldsymbol{y}] \\
\operatorname{Cov}_{X, Y}[\boldsymbol{x}, \boldsymbol{y}]=\mathbf{0}
\end{array}</script><h5 id="2-条件独立-Conditional-Independence"><a href="#2-条件独立-Conditional-Independence" class="headerlink" title="2.条件独立 Conditional Independence"></a>2.条件独立 Conditional Independence</h5><p>给定$Z$，两个随机变量$X, Y$条件独立,当且仅当:</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}, \boldsymbol{y} \mid \boldsymbol{z})=p(\boldsymbol{x} \mid \boldsymbol{z}) p(\boldsymbol{y} \mid \boldsymbol{z}) \quad \text { for all } \quad z \in \mathcal{Z} \tag{25}</script><p>$\mathcal{Z}$是随机变量$Z$的状态量集合.$X \perp Y \mid Z$表示给定$Z$情况下$X$条件独立$Y$,或者“我们已知$z$,关于$y$的信息不改变$x$的信息”。</p>
<p>公式25可以理解为“给定关于$z$的信息,  $x \ and \ y$  的分布的分解”。运用概率的积的法则,公式25左边展开可以得到:</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}, \boldsymbol{y} \mid \boldsymbol{z})=p(\boldsymbol{x} \mid \boldsymbol{y}, \boldsymbol{z}) p(\boldsymbol{y} \mid \boldsymbol{z}) \tag{26}</script><p>比较公式25、26右边部分,我们得到：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x} \mid \boldsymbol{y}, \boldsymbol{z}) = p(\boldsymbol{x} \mid \boldsymbol{z}) \tag{27}</script><h4 id="4-随机变量的内积"><a href="#4-随机变量的内积" class="headerlink" title="4. 随机变量的内积"></a>4. 随机变量的内积</h4><h5 id="1-两个随机变量的内积定义"><a href="#1-两个随机变量的内积定义" class="headerlink" title="1. 两个随机变量的内积定义"></a>1. 两个随机变量的内积定义</h5><p>如果我们有两个不相关随机变量$X，Y$,  uncorrelated random variable, covariance value is zero 有：</p>
<script type="math/tex; mode=display">
\mathbb{V}[x+y]=\mathbb{V}[x]+\mathbb{V}[y] \tag{28}</script><p>如果随机变量$X，Y$是不相关的,它们在对应向量空间是正交向量,应用毕达哥拉斯定理可以有如下示意图</p>
<center>    <img style="border-radius: 0.3125em;    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"     src="https://i.loli.net/2020/07/03/YWiBm5kDjK49uSq.png?=raw" width=40% height=40%>    
 <br>    <div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">随机变量X,Y内积示意图 引用自https://mml-book.com</div> </center>

<p>随机变量在向量空间可以被看着向量,并且我们定义内积来获得随机变量的几何性质。</p>
<script type="math/tex; mode=display">
\langle X, Y\rangle:=\operatorname{Cov}[x, y] \tag{29}</script><p>对0均值随机变量$X,Y$，我们得到内积。我们看到协方差矩阵是对称正定的，对每个参数都是线性的。随机变量的长度为：</p>
<script type="math/tex; mode=display">
\|X\|=\sqrt{\operatorname{Cov}[x, x]}=\sqrt{\mathbb{V}[x]}=\sigma[x] \tag{30}</script><p>其标准偏差。随机变量的”长”，是不确定的，但一个长为0的随机变量是确定的。其还有如下性质：</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\operatorname{Cov}[x, x]=0 \Longleftrightarrow 
x=0 \\
\operatorname{Cov}[\alpha x+z, y]= 
\alpha \operatorname{Cov}[x, y]+ 
\operatorname{Cov}[z, y] \text { for } \alpha \in \mathbb{R}
\end{array}</script><p>如果我们观察两个随机变量$X，Y$之间的角度$\theta$,我们得到：</p>
<script type="math/tex; mode=display">
\cos \theta=\frac{\langle X, Y\rangle}{\|X\|\|Y\|}=\frac{\operatorname{Cov}[x, y]}{\sqrt{\mathbb{V}[x] \mathbb{V}[y]}} \tag{31}</script><p>随机变量$X,Y$是正交的当且仅当$\operatorname{Cov}[x, y] = 0$，意味着它们是无关的。</p>
<h3 id="4-高斯分布"><a href="#4-高斯分布" class="headerlink" title="4. 高斯分布"></a>4. 高斯分布</h3><h4 id="1-什么是高斯分布"><a href="#1-什么是高斯分布" class="headerlink" title="1. 什么是高斯分布?"></a>1. 什么是高斯分布?</h4><p>二元随机变量$x_1, x_2$的高斯分布如下：    </p>
<center>    <img style="border-radius: 0.3125em;    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"     src="https://i.loli.net/2020/07/04/9hp2zKNoDm1HMXb.png?=raw" width=40% height=40%>    
 <br>    <div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">二元随机变量高斯分布示意图 引用自https://mml-book.com</div> </center>

<p>100个样本的高斯分布：</p>
<ul>
<li><p>a）一维实例</p>
</li>
<li><p>b）二维实例</p>
<center>    <img style="border-radius: 0.3125em;    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"     src="https://i.loli.net/2020/07/04/5JyxHIbhATvfzZl.png?=raw" width=80% height=80%>    
 <br>    <div style="color:orange; border-bottom: 1px solid #d9d9d9;    display: inline-block;    color: #999;    padding: 2px;">100个样本的高斯分布示意图 引用自https://mml-book.com</div> </center>


</li>
</ul>
<p>对于单一随机变量,高斯分布的概率密度函数定义为：</p>
<script type="math/tex; mode=display">
p\left(x \mid \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right) \tag{32}</script><p>以均值向量$\boldsymbol{\mu}$和协方差矩阵$\boldsymbol{\Sigma}$完全地特征化的多元随机变量的高斯分布可以定义为：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma})=(2 \pi)^{-\frac{D}{2}}|\boldsymbol{\Sigma}|^{-\frac{1}{2}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\top} \boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right) \tag{33}</script><p>其中, <script type="math/tex">\boldsymbol{x} \in \mathbb{R}^{D}, \ \ p(\boldsymbol{x})=\mathcal{N}(\boldsymbol{x} \mid \boldsymbol{\mu}, \boldsymbol{\Sigma}) \text { or } X \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})</script>。</p>
<p>当<script type="math/tex">\boldsymbol{\mu}=0</script> 且 <script type="math/tex">\boldsymbol{\Sigma}=\boldsymbol{I}</script>时，称作标准正态分布。</p>
<h4 id="2-多重高斯分布-Gaussians-的边界-Marginal-和条件-Conditional"><a href="#2-多重高斯分布-Gaussians-的边界-Marginal-和条件-Conditional" class="headerlink" title="2. 多重高斯分布 Gaussians 的边界 Marginal 和条件 Conditional"></a>2. 多重高斯分布 Gaussians 的边界 Marginal 和条件 Conditional</h4><p>我们清晰地按照级联状态  <script type="math/tex">[\boldsymbol{x}, \boldsymbol{y}]^T</script> 写出高斯分布:</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}, \boldsymbol{y})=\mathcal{N}\left(\left[\begin{array}{l}
\boldsymbol{\mu}_{x} \\
\boldsymbol{\mu}_{y}
\end{array}\right],\left[\begin{array}{cc}
\boldsymbol{\Sigma}_{x x} & \boldsymbol{\Sigma}_{x y} \\
\boldsymbol{\Sigma}_{y x} & \boldsymbol{\Sigma}_{y y}
\end{array}\right]\right) \tag{34}</script><p>其中，  <script type="math/tex">\boldsymbol{\Sigma }_{x x} = \operatorname{Cov}[\boldsymbol{x}, \boldsymbol{x}] \text{ and } \boldsymbol{\Sigma}_{y y}=\operatorname{Cov}[\boldsymbol{y}, \boldsymbol{y}]</script>   是  <script type="math/tex">\boldsymbol{x} \text{ and } \boldsymbol{y}</script>  边缘协方差矩阵。同时,   <script type="math/tex">\boldsymbol{\Sigma }_{x y} = \operatorname{Cov}[\boldsymbol{x}, \boldsymbol{y}]</script>  是  <script type="math/tex">\boldsymbol{x}</script> 和 <script type="math/tex">\boldsymbol{y}</script>  之间的互协方差矩阵。</p>
<p>条件分布conditional distribution  <script type="math/tex">p(\boldsymbol{x} \mid \boldsymbol{y})</script>  也是高斯分布,其定义为:</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(\boldsymbol{x} \mid \boldsymbol{y}) &=\mathcal{N}\left(\boldsymbol{\mu}_{x \mid y}, \boldsymbol{\Sigma}_{x \mid y}\right) \\
\boldsymbol{\mu}_{x \mid y} &=\boldsymbol{\mu}_{x}+\boldsymbol{\Sigma}_{x y} \boldsymbol{\Sigma}_{y y}^{-1}\left(\boldsymbol{y}-\boldsymbol{\mu}_{y}\right) \\ 
\boldsymbol{\Sigma}_{x \mid y} &=\boldsymbol{\Sigma}_{x x}-\boldsymbol{\Sigma}_{x y} \boldsymbol{\Sigma}_{y y}^{-1} \boldsymbol{\Sigma}_{y x}
\end{aligned} \tag{35}</script><p>注意，公式35计算均值时,  <script type="math/tex">\boldsymbol{y}-value</script>  是一个观察量而不是变量。</p>
<p>一个联合高斯分布<script type="math/tex">p(\boldsymbol{x}, \boldsymbol{y})</script>的边缘分布<script type="math/tex">p(\boldsymbol{x})</script>，其高斯分布应用sum rule计算给定为：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x})=\int p(\boldsymbol{x}, \boldsymbol{y}) d \boldsymbol{y}=\mathcal{N}\left(\boldsymbol{x} \mid \boldsymbol{\mu}_{x}, \boldsymbol{\Sigma}_{x x}\right)  \tag{36}</script><p>对应的结果也适用于$p(\boldsymbol{y})$,这通过边缘化$\boldsymbol{x}$来获得。</p>
<h4 id="3-高斯分布密度的积"><a href="#3-高斯分布密度的积" class="headerlink" title="3.  高斯分布密度的积"></a>3.  高斯分布密度的积</h4><p>两个高斯分布<script type="math/tex">\mathcal{N}(\boldsymbol{x} \mid \boldsymbol{a}, \boldsymbol{A}) \quad \mathcal{N}(\boldsymbol{x} \mid \boldsymbol{b}, \boldsymbol{B})</script>的积,是按<script type="math/tex">c \in \mathbb{R}</script>成比例的高斯分布,给定为<script type="math/tex">c  \mathcal{N}(\boldsymbol{x} \mid \boldsymbol{c}, \boldsymbol{C})</script>:</p>
<script type="math/tex; mode=display">
\begin{align}
\tag{37} \boldsymbol{C} &=\left(\boldsymbol{A}^{-1}+\boldsymbol{B}^{-1}\right)^{-1}  \\
\tag{38} \boldsymbol{c} &=\boldsymbol{C}\left(\boldsymbol{A}^{-1} \boldsymbol{a}+\boldsymbol{B}^{-1} \boldsymbol{b}\right) \\
\tag{39} c &=(2 \pi)^{-\frac{D}{2}}|\boldsymbol{A}+\boldsymbol{B}|^{-\frac{1}{2}} \exp \left(-\frac{1}{2}(\boldsymbol{a}-\boldsymbol{b})^{\top}(\boldsymbol{A}+\boldsymbol{B})^{-1}(\boldsymbol{a}-\boldsymbol{b})\right)
\end{align}</script><p>比例常数$c$，它可以按照高斯密度函数的形式，以$\boldsymbol{a}$或$\boldsymbol{b}$和一个”夸张的”协方差矩阵$\boldsymbol{A+B}$写作，如,$\mathcal{N}(\boldsymbol{a} \mid \boldsymbol{b}, \boldsymbol{A + B}) \text{ 或 } \mathcal{N}(\boldsymbol{b} \mid \boldsymbol{a}, \boldsymbol{A + B})$.</p>
<p>注意：为了记号简便,我们有时用$\mathcal{N}(\boldsymbol{x} \mid \boldsymbol{m}, \boldsymbol{S})$来描述高斯密度函数的形式，即使$\boldsymbol{x}$不是一个随机变量。当我们写作如下公式时，仅需要做前面的证明。</p>
<script type="math/tex; mode=display">
c=\mathcal{N}(\boldsymbol{a} \mid \boldsymbol{b}, \boldsymbol{A}+\boldsymbol{B})=\mathcal{N}(\boldsymbol{b} \mid \boldsymbol{a}, \boldsymbol{A}+\boldsymbol{B}) \tag{40}</script><h4 id="高斯分布的和、线性变换-Sums-and-Linear-Transformations"><a href="#高斯分布的和、线性变换-Sums-and-Linear-Transformations" class="headerlink" title="高斯分布的和、线性变换 Sums and Linear Transformations"></a>高斯分布的和、线性变换 Sums and Linear Transformations</h4><p>如果<script type="math/tex">X,\,Y</script>是独立的高斯随机变量，那么<script type="math/tex">\boldsymbol{x + y}</script>也是高斯分布，给定为：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x}+\boldsymbol{y})=\mathcal{N}\left(\boldsymbol{\mu}_{x}+\boldsymbol{\mu}_{y}, \boldsymbol{\Sigma}_{x}+\boldsymbol{\Sigma}_{y}\right) \tag{41}</script><h5 id="两个单一变量混合高斯分布密度"><a href="#两个单一变量混合高斯分布密度" class="headerlink" title="两个单一变量混合高斯分布密度"></a>两个单一变量混合高斯分布密度</h5><script type="math/tex; mode=display">
p(x)=\alpha p_{1}(x)+(1-\alpha) p_{2}(x) \tag{42}</script><p>这里标量$0&lt; \alpha &lt; 1$是混合权重,  <script type="math/tex">p(x_1) \text{和} p(x_2)</script>  是有不同参数的单一高斯分布密度,如， <script type="math/tex">(\mu_{1}, \sigma_{1}) \, \neq \, (\mu_{2}, \sigma_{2})</script>  。</p>
<p>混合高斯分布密度  $p(x)$  用每个随机变量的均值的权重之和来定义：</p>
<script type="math/tex; mode=display">
\mathbb{E}[x] = \alpha \mu_{1} + (1 - \alpha) \mu_{2} \tag{43}</script><p>混合高斯分布密度$p(x)$的方差给定为：</p>
<script type="math/tex; mode=display">
\mathbb{V}(x) = \left[\alpha \sigma_{1}^{2} + (1-\alpha)\sigma_{2}^{2} \right] + 
\left( \left[\alpha \mu_{1}^{2} + (1-\alpha)\mu_{2}^{2}\right] - \left[ \alpha \mu_{1} + (1-\alpha)\mu_{2} \right] ^{2}    \right) \tag{44}</script><p>证明:$\mathbb{E}[x]$</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbb{E}[x] &=\int_{-\infty}^{\infty} x p(x) \mathrm{d} x \\
&=\int_{-\infty}^{\infty} \alpha x p_{1}(x)+(1-\alpha) x p_{2}(x) \mathrm{d} x \\
&=\alpha \int_{-\infty}^{\infty} x p_{1}(x) \mathrm{d} x+(1-\alpha) \int_{-\infty}^{\infty} x p_{2}(x) \mathrm{d} x \\
&=\alpha \mu_{1}+(1-\alpha) \mu_{2} \tag{45}
\end{align}</script><p>而要证明$\mathbb{V}(x)$，得证明$\mathbb{E}(x^{2})$.</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbb{E}(x^{2}) &= \int_{-\infty}^{\infty} x^{2}p(x) \mathrm{d}x \\
 & = \int_{-\infty}^{\infty} \alpha x^{2} p_{1}(x) + (1 - \alpha)x^{2}p_{2}(x) \mathrm{d}x \\
 & = \alpha \int_{-\infty}^{\infty}x^{2}p_{1}(x) \mathrm{d}x +  (1 - \alpha)\int_{-\infty}^{\infty}x^{2}p_{2}(x) \mathrm{d}x \\
 & = \alpha(\mu_{1}^{2} + \sigma_{1}^{2}) + (1 - \alpha)(\mu_{2}^{2} + \sigma_{2}^{2}) \tag{46}
\end{align}</script><p>公式46最后两步是因为:$\sigma^{2} = \mathbb{E}[x^2] - \mu^{2}$。重新整理就是随机变量平方的均值等于均值和方差平方和。因此，方差可以定义为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbb{V}[x]=& \mathbb{E}\left[x^{2}\right]-(\mathbb{E}[x])^{2} \\
=& \alpha\left(\mu_{1}^{2}+\sigma_{1}^{2}\right)+(1-\alpha)\left(\mu_{2}^{2}+\sigma_{2}^{2}\right)-\left(\alpha \mu_{1}+(1-\alpha) \mu_{2}\right)^{2} \\
=&\left[\alpha \sigma_{1}^{2}+(1-\alpha) \sigma_{2}^{2}\right] \\
&+\left(\left[\alpha \mu_{1}^{2}+(1-\alpha) \mu_{2}^{2}\right]-\left[\alpha \mu_{1}+(1-\alpha) \mu_{2}\right]^{2}\right) \tag{47}
\end{align}</script><p>注意：前面的偏差可以应用到任何密度函数，但自从高斯分布完全由均值和方差决定后，混合密度函数也可以确定了。</p>
<h5 id="总方差定理-Law-of-total-variance"><a href="#总方差定理-Law-of-total-variance" class="headerlink" title="总方差定理 Law of total variance"></a>总方差定理 Law of total variance</h5><p>通常指对于两个随机变量$X \, 和 \, Y$，有：</p>
<script type="math/tex; mode=display">
\mathbb{V}_{X}[x] = \mathbb{E}_Y \left[\mathbb{V}_{X} \left[x \mid y \right] \right] + \mathbb{V}_{Y} \left[\mathbb{E}_{X} \left[x \mid y \right] \right]</script><p>即条件方差的期望加上条件均值的方差。</p>
<p>我们认为二元高斯随机变量$X$，对其应用线性变换$\boldsymbol{Ax}$。结果是一个有均值zero协方差为$\boldsymbol{A}\boldsymbol{A}^{\top}$高斯分布。观察到，加上一个常数向量将会改变分布的均值，不影响其方差，那么，随机变量$\boldsymbol{x + \mu}$有均值$\boldsymbol{\mu}$和单位协方差矩阵。因此，高斯分布进行任何线性、仿射变换后都是高斯分布。</p>
<p>考虑高斯分布随机变量$X \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$,对于给定恰当形状的矩阵$\boldsymbol{A}$，让$Y$成为$\boldsymbol{x}$进行$\boldsymbol{y = Ax}$变换后的的随机变量。我们利用如下线性操作来计算$\boldsymbol{y}$</p>
<p>的均值：</p>
<script type="math/tex; mode=display">
\mathbb{E}[\boldsymbol{y}] = \mathbb{E}[\boldsymbol{Ax}]= \boldsymbol{A}\mathbb{E}[\boldsymbol{x}] = \boldsymbol{A\mu} \tag{48}</script><p>方差：</p>
<script type="math/tex; mode=display">
\mathbb{V} \left[ \boldsymbol{y}\right] = \mathbb{V} \left[ \boldsymbol{Ax}\right] = \boldsymbol{A} \mathbb{V} \left[ \boldsymbol{x}\right]\boldsymbol{A}^{\top}  =\boldsymbol{A} \boldsymbol{\Sigma} \boldsymbol{A}^{\top} \tag{49}</script><p>随机变量$\boldsymbol{y}$分布服从于：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{y})=\mathcal{N}\left(\boldsymbol{y} \mid \boldsymbol{A} \boldsymbol{\mu}, \boldsymbol{A} \boldsymbol{\Sigma} \boldsymbol{A}^{\top}\right) \tag{50}</script><p>现在，我们再考虑相反的变换：当一个随机变量有均值， 且是另一个随机变量的线性变换。对于给定一个满秩矩阵$\boldsymbol{A} \in \mathbb{R}^{M \times N}$,当 $M \ge N$, $\boldsymbol{y} \in \mathbb{R}^{M}$是一个均值为$\boldsymbol{Ax}$的高斯随机变量， 即：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{y})=\mathcal{N}\left(\boldsymbol{y} \mid \boldsymbol{Ax},\, \boldsymbol{\Sigma} \right) \tag{51}</script><p>其对应概率分布$p(\boldsymbol{x})$是什么？如果 $p(\boldsymbol{A})$是可逆的，我们可以写作$\boldsymbol{x} = \boldsymbol{A}^{-1}\boldsymbol{y}$,应用前面提到的变换。然而，通常$\boldsymbol{A}$是不可逆，我们使用相似的方法即伪逆。我们两边同乘$\boldsymbol{A}^{\top}$,然后逆变换$\boldsymbol{A}^{\top}\boldsymbol{A}$,它是对称正定的，给我们如下联系：</p>
<script type="math/tex; mode=display">
\boldsymbol{y}=\boldsymbol{A} \boldsymbol{x} \Longleftrightarrow\left(\boldsymbol{A}^{\top} \boldsymbol{A}\right)^{-1} \boldsymbol{A}^{\top} \boldsymbol{y}=\boldsymbol{x} \tag{52}</script><p>因此，$\boldsymbol{y}$的逆变换是$\boldsymbol{x}$，我们可以得到：</p>
<script type="math/tex; mode=display">
p(\boldsymbol{x})=\mathcal{N}\left(\boldsymbol{x} \mid\left(\boldsymbol{A}^{\top} \boldsymbol{A}\right)^{-1} \boldsymbol{A}^{\top} \boldsymbol{y},\left(\boldsymbol{A}^{\top} \boldsymbol{A}\right)^{-1} \boldsymbol{A}^{\top} \boldsymbol{\Sigma} \boldsymbol{A}\left(\boldsymbol{A}^{\top} \boldsymbol{A}\right)^{-1}\right) \tag{53}</script><h3 id="5-Conjugacy-and-the-Exponential-Family"><a href="#5-Conjugacy-and-the-Exponential-Family" class="headerlink" title="5. Conjugacy and the Exponential Family"></a>5. Conjugacy and the Exponential Family</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">miller</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://aigonna.com/2020/04/04/M4ML_Chapter06-Probability-and-Distributions/">http://aigonna.com/2020/04/04/M4ML_Chapter06-Probability-and-Distributions/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://aigonna.com" target="_blank">aigonna</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/Mathematic-for-machine-learning-%E7%AC%94%E8%AE%B0/">Mathematic for machine learning 笔记</a><a class="post-meta__tags" href="/tags/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/">高斯分布</a><a class="post-meta__tags" href="/tags/Probability/">Probability</a></div><div class="post_share"><div class="social-share" data-image="/img/ach.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/05/15/DS_4.%E4%BA%8C%E5%8F%89%E6%A0%91/"><img class="prev-cover" src="/img/imgs/1.jpg" onerror="onerror=null;src='/img/imgs/0.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">4. 二叉树</div></div></a></div><div class="next-post pull-right"><a href="/2020/04/01/M4ML_Chapter05-Vector-Calculus/"><img class="next-cover" src="/img/imgs/15.jpg" onerror="onerror=null;src='/img/imgs/0.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Chapter05:Vector calculus</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/04/01/M4ML_Chapter05-Vector-Calculus/" title="Chapter05:Vector calculus"><img class="cover" src="/img/imgs/15.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-01</div><div class="title">Chapter05:Vector calculus</div></div></a></div><div><a href="/2020/03/28/M4ML_Chapter04-Matrix-Decompositions/" title="Chapter04:Matrix Decompositions"><img class="cover" src="/img/imgs/14.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-28</div><div class="title">Chapter04:Matrix Decompositions</div></div></a></div><div><a href="/2020/06/29/机器学习的数学基础Lecture11/" title="Lecture 11  PageRank and Ridge Regression"><img class="cover" src="/img/imgs/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-29</div><div class="title">Lecture 11  PageRank and Ridge Regression</div></div></a></div><div><a href="/2020/06/28/机器学习的数学基础Lecture10/" title="Lecture 10 More on the SVD in Machine Learning"><img class="cover" src="/img/imgs/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-28</div><div class="title">Lecture 10 More on the SVD in Machine Learning</div></div></a></div><div><a href="/2020/06/24/机器学习的数学基础Lecture9/" title="Lecture 9 The SVD in Machine Learning"><img class="cover" src="/img/imgs/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-24</div><div class="title">Lecture 9 The SVD in Machine Learning</div></div></a></div><div><a href="/2020/06/23/机器学习的数学基础Lecture8/" title="Lecture 8 The Singular Value Decomposition"><img class="cover" src="/img/imgs/8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-06-23</div><div class="title">Lecture 8 The Singular Value Decomposition</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-06-Probability-and-Distributions"><span class="toc-text">Chapter 06: Probability and Distributions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Sum-Rule-Product-Rule-and-Bayes%E2%80%99-Theorem"><span class="toc-text">1. Sum Rule, Product Rule, and Bayes’ Theorem</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Likelihood-function"><span class="toc-text">1. Likelihood function</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E8%BE%B9%E7%BC%98%E4%BC%BC%E7%84%B6-%E8%AF%81%E6%8D%AE"><span class="toc-text">2.  边缘似然&#x2F;证据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9D%87%E5%80%BC%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="toc-text">2. 均值和协方差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%9C%9F%E6%9C%9B%E5%80%BC"><span class="toc-text">1. 期望值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%9D%87%E5%80%BC"><span class="toc-text">2. 均值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%8D%8F%E6%96%B9%E5%B7%AE-Covariance-%E5%AE%9A%E4%B9%89%E5%8F%8A%E6%8E%A8%E5%AF%BC"><span class="toc-text">3. 协方差(Covariance)定义及推导</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%A4%9A%E5%85%83%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-text">4. 多元随机变量的方差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E6%96%B9%E5%B7%AE"><span class="toc-text">5. 方差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E7%9B%B8%E5%85%B3"><span class="toc-text">6. 相关</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%BB%8F%E9%AA%8C%E5%9D%87%E5%80%BC%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="toc-text">3. 经验均值和协方差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%BB%8F%E9%AA%8C%E5%9D%87%E5%80%BC%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="toc-text">1. 经验均值和协方差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%96%B9%E5%B7%AE%E7%9A%843%E7%A7%8D%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="toc-text">2. 方差的3种表达式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%A0%87%E5%87%86%E6%96%B9%E5%B7%AE%E5%AE%9A%E4%B9%89"><span class="toc-text">1. 标准方差定义</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%96%B9%E5%B7%AE%E7%9A%84%E5%8E%9F%E5%A7%8B%E5%88%86%E6%95%B0%E5%85%AC%E5%BC%8F"><span class="toc-text">2. 方差的原始分数公式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-The-sum-of-N-2-pairwise-differences-is-the-empirical-variance-of-the-observations"><span class="toc-text">3. The sum of $N^{2}$ pairwise differences is the empirical variance of the observations</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Statistical-Independence-%E7%8B%AC%E7%AB%8B"><span class="toc-text">3. Statistical Independence(独立)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%8B%AC%E7%AB%8B"><span class="toc-text">1. 独立</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B-Conditional-Independence"><span class="toc-text">2.条件独立 Conditional Independence</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%86%85%E7%A7%AF"><span class="toc-text">4. 随机变量的内积</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E4%B8%A4%E4%B8%AA%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%86%85%E7%A7%AF%E5%AE%9A%E4%B9%89"><span class="toc-text">1. 两个随机变量的内积定义</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-text">4. 高斯分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-text">1. 什么是高斯分布?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%A4%9A%E9%87%8D%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83-Gaussians-%E7%9A%84%E8%BE%B9%E7%95%8C-Marginal-%E5%92%8C%E6%9D%A1%E4%BB%B6-Conditional"><span class="toc-text">2. 多重高斯分布 Gaussians 的边界 Marginal 和条件 Conditional</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%AF%86%E5%BA%A6%E7%9A%84%E7%A7%AF"><span class="toc-text">3.  高斯分布密度的积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E7%9A%84%E5%92%8C%E3%80%81%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2-Sums-and-Linear-Transformations"><span class="toc-text">高斯分布的和、线性变换 Sums and Linear Transformations</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E5%8D%95%E4%B8%80%E5%8F%98%E9%87%8F%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%AF%86%E5%BA%A6"><span class="toc-text">两个单一变量混合高斯分布密度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E6%96%B9%E5%B7%AE%E5%AE%9A%E7%90%86-Law-of-total-variance"><span class="toc-text">总方差定理 Law of total variance</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Conjugacy-and-the-Exponential-Family"><span class="toc-text">5. Conjugacy and the Exponential Family</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021&nbsp;<i style="color:#FF6A6A;animation: announ_animation 0.8s linear infinite;"class="fas fa-heart"></i> By miller</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      //tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'forest',
      })
      false && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: '5sVUTO1MTpgoo7pDynh6zYEM-MdYXbMMI',
      appKey: 'vPUvOT1iP6YqcPPtYSqf8F7A',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script><h4>AIgonna</h4></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script></div></body></html>